{"cells":[{"cell_type":"markdown","metadata":{"id":"vc7wbgTVhZfL"},"source":["![ga4](https://www.google-analytics.com/collect?v=2&tid=G-6VDTYWLKX6&cid=1&en=page_view&sid=1&dl=statmike%2Fvertex-ai-mlops%2Farchitectures%2Ftracking%2Fsetup%2Fgithub&dt=GitHub+Metrics+-+3+-+Commits+-+Incremental+Update+Cloud+Function.ipynb)\n","\n","# GitHub Metrics: Commit History Cloud Function For Incremental Updates\n","\n","The notebooks for commit history in steps 1 and 2 created and initial setup of tables in the BigQuery datasets `github_metrics` and `reporting`.  Tables are `commits` and `commits_files` within both.  The logic for incrementally updating these is also tested and developed in those notebooks.\n","\n","This notebook creates a Cloud Function to run the code that incrementally updates the tables in the datasets and schedules it to run daily using Pub/Sub and Cloud Scheduler.\n","\n","**Notes**\n","- The Pub/Sub topic is shared between all step 3 notebooks\n","- The Cloud Scheduler is shared between all step 3 notebooks"]},{"cell_type":"markdown","metadata":{"id":"Nw1ZZWFyXw2L"},"source":["---\n","## Colab Setup\n","\n","To run this notebook in Colab click [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/statmike/vertex-ai-mlops/blob/main/architectures/tracking/setup/github/GitHub%20Metrics%20-%203%20-%20Commits%20-%20Incremental%20Update%20Cloud%20Function.ipynb) and run the cells in this section.  Otherwise, skip this section.\n","\n","This cell will authenticate to GCP (follow prompts in the popup)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MWl8BI5apkcI"},"outputs":[],"source":["PROJECT_ID = 'vertex-ai-mlops-369716' # replace with project ID"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15967,"status":"ok","timestamp":1677586474011,"user":{"displayName":"Mike Henderson","userId":"11664017018095232389"},"user_tz":300},"id":"WdZkhxNLoVNY","outputId":"b59be1c9-1c83-416a-bd94-bd617ca5644a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Updated property [core/project].\n"]}],"source":["try:\n","    import google.colab\n","    from google.colab import auth\n","    auth.authenticate_user()\n","    !gcloud config set project {PROJECT_ID}\n","except Exception:\n","    pass"]},{"cell_type":"markdown","metadata":{"id":"_-QlhG8rZDvT"},"source":["---\n","## Package Installs (if needed)\n","\n","This notebook uses the Python Clients for\n","- Google Service Usage\n","    - to enable APIs\n","- Cloud Pub/Sub\n","- Cloud Functions\n","- Cloud Scheduler\n","\n","The cells below check to see if the required Python libraries are installed.  If any are not it will print a message to do the install with the associated pip command to use.  These installs must be completed before continuing this notebook."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14111,"status":"ok","timestamp":1677586491218,"user":{"displayName":"Mike Henderson","userId":"11664017018095232389"},"user_tz":300},"id":"HP8pLhQMZEMe","outputId":"abc80815-6418-46dd-ba69-0fe3c2a9581a"},"outputs":[{"output_type":"stream","name":"stdout","text":["You need to pip install google-cloud-service-usage\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 KB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hYou need to pip install google-cloud-pubsub\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.0/243.0 KB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hYou need to pip install google-cloud-functions\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.6/125.6 KB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hYou need to pip install google-cloud-scheduler\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.5/98.5 KB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["try:\n","    import google.cloud.service_usage_v1\n","except ImportError:\n","    print('You need to pip install google-cloud-service-usage')\n","    !pip install google-cloud-service-usage -q\n","\n","try:\n","    import google.cloud.pubsub\n","except ImportError:\n","    print('You need to pip install google-cloud-pubsub')\n","    !pip install google-cloud-pubsub -q\n","\n","try:\n","    import google.cloud.functions\n","except ImportError:\n","    print('You need to pip install google-cloud-functions')\n","    !pip install google-cloud-functions -q\n","\n","try:\n","    import google.cloud.scheduler\n","except ImportError:\n","    print('You need to pip install google-cloud-scheduler')\n","    !pip install google-cloud-scheduler -q"]},{"cell_type":"markdown","metadata":{"id":"tVA5SciOoNlf"},"source":["---\n","## Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":1020,"status":"ok","timestamp":1677586492233,"user":{"displayName":"Mike Henderson","userId":"11664017018095232389"},"user_tz":300},"id":"pCPIhNOomdyi","outputId":"789b9d45-7cf6-4249-ab4f-2f29000ffa5d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'vertex-ai-mlops-369716'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":4}],"source":["project = !gcloud config get-value project\n","PROJECT_ID = project[0]\n","PROJECT_ID"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JwYJTkWAoY5U"},"outputs":[],"source":["REGION = 'us-central1'\n","\n","github_user = 'statmike'\n","github_repo = 'vertex-ai-mlops'\n","\n","BQ_PROJECT = PROJECT_ID\n","BQ_DATASET = 'github_metrics'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wjIPLHPWoY8O"},"outputs":[],"source":["import requests\n","import json\n","import time\n","from datetime import datetime\n","import pandas as pd\n","from io import StringIO\n","import os, shutil\n","\n","from google.cloud import bigquery\n","from google.cloud import storage\n","\n","from google.cloud import service_usage_v1\n","from google.cloud import pubsub_v1\n","from google.cloud import functions_v1\n","from google.cloud import scheduler_v1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YyZ2WKRtoY-R"},"outputs":[],"source":["bq = bigquery.Client(project = PROJECT_ID)\n","gcs = storage.Client(project = PROJECT_ID)\n","\n","su_client = service_usage_v1.ServiceUsageClient()\n","pubsub_pubclient = pubsub_v1.PublisherClient() \n","functions_client = functions_v1.CloudFunctionsServiceClient()\n","scheduler_client = scheduler_v1.CloudSchedulerClient()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4Uy3ZhfdglKE"},"outputs":[],"source":["DIR = 'temp'\n","!rm -rf {DIR}\n","!mkdir -p {DIR}"]},{"cell_type":"markdown","metadata":{"id":"_LnkZxK8b_Rx"},"source":["---\n","## Enable APIs\n","\n","Using Cloud Functions, Cloud Pub/Sub and Cloud Scheduler requires enabling these APIs for the Google Cloud Project.  Additionally, Cloud Functions uses Cloud Build which also need to be enabled.\n","\n","Options for enabeling these.  In this notebook option 2 is used.\n"," 1. Use the APIs & Services page in the console: https://console.cloud.google.com/apis\n","     - `+ Enable APIs and Services`\n","     - Search for Cloud Build and Enable\n","     - Search for Artifact Registry and Enable\n"," 2. Use [Google Service Usage](https://cloud.google.com/service-usage/docs) API from Python\n","     - [Python Client For Service Usage](https://github.com/googleapis/python-service-usage)\n","     - [Python Client Library Documentation](https://cloud.google.com/python/docs/reference/serviceusage/latest)\n","     \n","The following code cells use the Service Usage Client to:\n","- get the state of the service\n","- if 'DISABLED':\n","    - Try enabling the service and return the state after trying\n","- if 'ENABLED' print the state for confirmation"]},{"cell_type":"markdown","metadata":{"id":"5s4qC8wKxy7y"},"source":["### IAM\n","The API may be needed for creating a service account to run the Cloud Function"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":244,"status":"ok","timestamp":1677586545658,"user":{"displayName":"Mike Henderson","userId":"11664017018095232389"},"user_tz":300},"id":"qJstNPsVxzU3","outputId":"dca36275-7319-488f-d90c-9df7a56cfe69"},"outputs":[{"output_type":"stream","name":"stdout","text":["IAM already enabled for project: vertex-ai-mlops-369716\n"]}],"source":["iam = su_client.get_service(\n","    request = service_usage_v1.GetServiceRequest(\n","        name = f'projects/{PROJECT_ID}/services/iam.googleapis.com'\n","    )\n",").state.name\n","\n","\n","if iam == 'DISABLED':\n","    print(f'IAM is currently {iam} for project: {PROJECT_ID}')\n","    print(f'Trying to Enable...')\n","    operation = su_client.enable_service(\n","        request = service_usage_v1.EnableServiceRequest(\n","            name = f'projects/{PROJECT_ID}/services/iam.googleapis.com'\n","        )\n","    )\n","    response = operation.result()\n","    if response.service.state.name == 'ENABLED':\n","        print(f'IAM is now enabled for project: {PROJECT_ID}')\n","    else:\n","        print(response)\n","else:\n","    print(f'IAM already enabled for project: {PROJECT_ID}')"]},{"cell_type":"markdown","metadata":{"id":"1dwUhJJ2cKHc"},"source":["### Cloud Pub/Sub"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":238,"status":"ok","timestamp":1677586549776,"user":{"displayName":"Mike Henderson","userId":"11664017018095232389"},"user_tz":300},"id":"sT8dJC1JcKqQ","outputId":"dcb2cda4-6e50-49df-bf44-30fd5ca3fa51"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloud Pub/Sub already enabled for project: vertex-ai-mlops-369716\n"]}],"source":["pubsub = su_client.get_service(\n","    request = service_usage_v1.GetServiceRequest(\n","        name = f'projects/{PROJECT_ID}/services/pubsub.googleapis.com'\n","    )\n",").state.name\n","\n","\n","if pubsub == 'DISABLED':\n","    print(f'Cloud Pub/Sub is currently {pubsub} for project: {PROJECT_ID}')\n","    print(f'Trying to Enable...')\n","    operation = su_client.enable_service(\n","        request = service_usage_v1.EnableServiceRequest(\n","            name = f'projects/{PROJECT_ID}/services/pubsub.googleapis.com'\n","        )\n","    )\n","    response = operation.result()\n","    if response.service.state.name == 'ENABLED':\n","        print(f'Cloud Pub/Sub is now enabled for project: {PROJECT_ID}')\n","    else:\n","        print(response)\n","else:\n","    print(f'Cloud Pub/Sub already enabled for project: {PROJECT_ID}')"]},{"cell_type":"markdown","metadata":{"id":"S3JwTpSLcLD8"},"source":["### Cloud Functions"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":314,"status":"ok","timestamp":1677586553653,"user":{"displayName":"Mike Henderson","userId":"11664017018095232389"},"user_tz":300},"id":"6IMhH26acLj6","outputId":"fcdde3d4-f8cf-42d8-b6c0-78cfe526cc46"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloud Functions already enabled for project: vertex-ai-mlops-369716\n"]}],"source":["cloudfunctions = su_client.get_service(\n","    request = service_usage_v1.GetServiceRequest(\n","        name = f'projects/{PROJECT_ID}/services/cloudfunctions.googleapis.com'\n","    )\n",").state.name\n","\n","\n","if cloudfunctions == 'DISABLED':\n","    print(f'Cloud Functions is currently {cloudfunctions} for project: {PROJECT_ID}')\n","    print(f'Trying to Enable...')\n","    operation = su_client.enable_service(\n","        request = service_usage_v1.EnableServiceRequest(\n","            name = f'projects/{PROJECT_ID}/services/cloudfunctions.googleapis.com'\n","        )\n","    )\n","    response = operation.result()\n","    if response.service.state.name == 'ENABLED':\n","        print(f'Cloud Functions is now enabled for project: {PROJECT_ID}')\n","    else:\n","        print(response)\n","else:\n","    print(f'Cloud Functions already enabled for project: {PROJECT_ID}')"]},{"cell_type":"markdown","metadata":{"id":"F3NMT-u2cL8o"},"source":["### Cloud Scheduler"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":291,"status":"ok","timestamp":1677586557229,"user":{"displayName":"Mike Henderson","userId":"11664017018095232389"},"user_tz":300},"id":"WV5-Tl8CcMah","outputId":"345f870c-946d-4c86-dd65-49918e164186"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloud Scheduler already enabled for project: vertex-ai-mlops-369716\n"]}],"source":["cloudscheduler = su_client.get_service(\n","    request = service_usage_v1.GetServiceRequest(\n","        name = f'projects/{PROJECT_ID}/services/cloudscheduler.googleapis.com'\n","    )\n",").state.name\n","\n","\n","if cloudscheduler == 'DISABLED':\n","    print(f'Cloud Scheduler is currently {cloudscheduler} for project: {PROJECT_ID}')\n","    print(f'Trying to Enable...')\n","    operation = su_client.enable_service(\n","        request = service_usage_v1.EnableServiceRequest(\n","            name = f'projects/{PROJECT_ID}/services/cloudscheduler.googleapis.com'\n","        )\n","    )\n","    response = operation.result()\n","    if response.service.state.name == 'ENABLED':\n","        print(f'Cloud Scheduler is now enabled for project: {PROJECT_ID}')\n","    else:\n","        print(response)\n","else:\n","    print(f'Cloud Scheduler already enabled for project: {PROJECT_ID}')"]},{"cell_type":"markdown","metadata":{"id":"uXkO3We2opgE"},"source":["### Cloud Build \n","Used By Cloud Functions"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":276,"status":"ok","timestamp":1677586559749,"user":{"displayName":"Mike Henderson","userId":"11664017018095232389"},"user_tz":300},"id":"cKNT0f1qop8s","outputId":"2ea124db-1e6e-496c-cd14-079467b1cc4c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloud Build already enabled for project: vertex-ai-mlops-369716\n"]}],"source":["cloudbuild = su_client.get_service(\n","    request = service_usage_v1.GetServiceRequest(\n","        name = f'projects/{PROJECT_ID}/services/cloudbuild.googleapis.com'\n","    )\n",").state.name\n","\n","\n","if cloudbuild == 'DISABLED':\n","    print(f'Cloud Build is currently {cloudbuild} for project: {PROJECT_ID}')\n","    print(f'Trying to Enable...')\n","    operation = su_client.enable_service(\n","        request = service_usage_v1.EnableServiceRequest(\n","            name = f'projects/{PROJECT_ID}/services/cloudbuild.googleapis.com'\n","        )\n","    )\n","    response = operation.result()\n","    if response.service.state.name == 'ENABLED':\n","        print(f'Cloud Build is now enabled for project: {PROJECT_ID}')\n","    else:\n","        print(response)\n","else:\n","    print(f'Cloud Build already enabled for project: {PROJECT_ID}')"]},{"cell_type":"markdown","metadata":{"id":"R8C45WQpaHIB"},"source":["---\n","## Pub/Sub\n","Use a Pub/Sub topic to trigger a Cloud Function to run.  The topic will be able to receive message manually or on a schedule from Cloud Scheduler.\n","\n","The main concepts:\n","- Topic - a feed of messages\n","     - Publish - send a new message to a topic\n","     - Subscription - receive messages that arrive on topic\n","          - Push - the subscriber has new messages pushed to it\n","          - Pull - the subscriber request new messages by pulling them\n","          \n","In this example, a topic will be set up for daily runs of metric functions.  Publishing a new message to this topic will trigger one or more Cloud Functions to run like the one setup below.  The Cloud Funtion will have a push subscription to the topic."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oieCXgTJaBzf"},"outputs":[],"source":["PUBSUB_TOPIC = 'daily_metrics_triggers'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"73xvkrPAbFVI"},"outputs":[],"source":["topic = ''\n","for topic in pubsub_pubclient.list_topics(project = f'projects/{PROJECT_ID}'):\n","    if topic.name.endswith(PUBSUB_TOPIC):\n","        break\n","    else: topic = ''"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1677586565580,"user":{"displayName":"Mike Henderson","userId":"11664017018095232389"},"user_tz":300},"id":"UlsN_SjKbFSn","outputId":"c68d4e58-0e3c-4823-8286-8ce459254f36"},"outputs":[{"output_type":"stream","name":"stdout","text":["name: \"projects/vertex-ai-mlops-369716/topics/daily_metrics_triggers\"\n","\n"]}],"source":["if topic:\n","    print(topic)\n","else:\n","    topic = pubsub_pubclient.create_topic(\n","        name = pubsub_pubclient.topic_path(PROJECT_ID, PUBSUB_TOPIC)\n","    )\n","    print(topic)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":104,"status":"ok","timestamp":1677586569392,"user":{"displayName":"Mike Henderson","userId":"11664017018095232389"},"user_tz":300},"id":"xRoSIOtC7IQF","outputId":"890281ac-5e2c-4408-e634-23fe66ab4b88"},"outputs":[{"output_type":"stream","name":"stdout","text":["Review The Pub/Sub Topic In The Console:\n","https://console.cloud.google.com/cloudpubsub/topic/list?project=vertex-ai-mlops-369716\n"]}],"source":["print(f'Review The Pub/Sub Topic In The Console:\\nhttps://console.cloud.google.com/cloudpubsub/topic/list?project={PROJECT_ID}')"]},{"cell_type":"markdown","metadata":{"id":"kaK6itFkgF80"},"source":["---\n","## Cloud Function\n","\n","Create a Cloud Funtion that runs the incremental update code for the tables in the dataset `github_metrics`.  The method below creates code files and zips them for storage on Cloud Storage as a source to the Cloud Function."]},{"cell_type":"markdown","metadata":{"id":"Jew-vd3XggLq"},"source":["### Create Files"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kpyBT84nbFPu"},"outputs":[],"source":["if os.path.exists(f'{DIR}/function'): shutil.rmtree(f'{DIR}/function')\n","os.makedirs(f'{DIR}/function')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":284,"status":"ok","timestamp":1677586573571,"user":{"displayName":"Mike Henderson","userId":"11664017018095232389"},"user_tz":300},"id":"LrXx5dQPbFNA","outputId":"736efa92-7fac-4161-982a-2188d945bbd5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Writing temp/function/requirements.txt\n"]}],"source":["%%writefile {DIR}/function/requirements.txt\n","pandas\n","db-dtypes\n","google-cloud-bigquery\n","google-cloud-storage"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1677586574724,"user":{"displayName":"Mike Henderson","userId":"11664017018095232389"},"user_tz":300},"id":"KENNnOrbbFJV","outputId":"afe38c2c-c920-4011-c9c3-3f94e522c2ce"},"outputs":[{"output_type":"stream","name":"stdout","text":["Writing temp/function/main.py\n"]}],"source":["%%writefile {DIR}/function/main.py\n","\n","# packages\n","import base64\n","import requests\n","import json\n","import pandas as pd\n","import os\n","from google.cloud import bigquery\n","#from google.cloud import storage\n","\n","\n","# clients\n","bq = bigquery.Client()\n","#gcs = storage.Client()\n","\n","\n","# parameters\n","github_user = 'statmike'\n","github_repo = 'vertex-ai-mlops'\n","BQ_DATASET = 'github_metrics'\n","github_api_url = f'https://api.github.com/repos/{github_user}/{github_repo}'\n","pat = os.getenv('GITHUB_PAT')\n","\n","\n","# helper function\n","def metric_get(metric_type):\n","  response = requests.get(f'{github_api_url}/{metric_type}', headers = {'Authorization': f'Bearer {pat}', 'Accept': 'application/vnd.github+json'})\n","  while response.status_code == 202:\n","      time.sleep(10)\n","      response = requests.get(f'{github_api_url}/{metric_type}', headers = {'Authorization': f'Bearer {pat}', 'Accept': 'application/vnd.github+json'})\n","  return response\n","\n","\n","# the function\n","def collect(event, context):\n","\n","    # print inputs to Cloud Function\n","    function_inputs = json.loads(base64.b64decode(event['data']).decode('utf-8'))\n","    print(function_inputs)\n","    PROJECT_ID = function_inputs['PROJECT_ID']\n","    BQ_PROJECT = PROJECT_ID\n","\n","    # START: Content from notebook: GitHub Metrics - 1 - Commits\n","\n","    # Read Commits From GitHub\n","    page_size = 100\n","    page = 1\n","    raw_commits = []\n","    while page_size == 100:\n","      response = requests.get(f'{github_api_url}/commits?per_page=100&page={page}', headers = {'Authorization': f'Bearer {pat}', 'Accept': 'application/vnd.github+json'})\n","      new_page = json.loads(response.text)\n","      if response.status_code == 200:\n","        raw_commits += new_page\n","        page_size = len(new_page)\n","        page +=1\n","      else: break\n","\n","    # parse Commits into list of dicts: one for each commit\n","    commits = []\n","    for i, c in enumerate(raw_commits):\n","      author = c['commit']['author']['name']\n","      author2 = ''\n","      if 'author' in c and c['author']:\n","        if 'login' in c['author']: author2 = c['author']['login']\n","\n","      # refined author with logic:\n","      if author2: refined_author = author2\n","      else: refined_author = author \n","\n","      commits += [{\n","          'sha': c['sha'],\n","          'datetime': c['commit']['committer']['date'],\n","          'url': c['html_url'],\n","          'message': c['commit']['message'],\n","          'author': refined_author\n","      }]\n","\n","    # create pandas dataframe of commits\n","    commits = pd.DataFrame(commits)\n","    #commits['datetime'] = pd.to_datetime(commits['datetime'], infer_datetime_format = True)\n","    commits.loc[commits['author'].str.lower() == 'mike henderson', 'author'] = 'statmike'\n","\n","    # look through prior commits, make a list of which commits are new\n","    prior_commits = bq.query(query = f\"\"\"SELECT sha FROM `{BQ_PROJECT}.{BQ_DATASET}.commits`\"\"\").to_dataframe()\n","    new_commits = pd.merge(prior_commits, commits, on = 'sha', how = 'outer', indicator = True)\n","    new_commits = new_commits[new_commits['_merge'] == 'right_only'].drop('_merge', axis = 1)\n","\n","    # if new commits then update to BigQuery\n","    if new_commits.shape[0] > 0:\n","      new_commits_job = bq.load_table_from_dataframe(\n","          dataframe = new_commits,\n","          destination = bigquery.TableReference.from_string(f\"{BQ_PROJECT}.{BQ_DATASET}.commits\"),\n","          job_config = bigquery.LoadJobConfig(\n","              write_disposition = 'WRITE_APPEND', # WRITE_TRUNCATE = replace if exists, WRITE_APPEND = append if exists, WRITE_EMPTY = write new but dont overwrite\n","              autodetect = True # detect schema\n","          )\n","      )\n","      new_commits_job.result()\n","\n","    # if new commits, retrieve files associated with the commits, parse the data into dataframe, append to BigQuery table\n","    if new_commits.shape[0] > 0:\n","      # retrieve files for new commits:\n","      sha = list(new_commits['sha'])\n","      raw_files = []\n","      for s in sha:\n","        page = 1\n","        response = requests.get(f'{github_api_url}/commits/{s}?per_page=100&page={page}', headers = {'Authorization': f'Bearer {pat}', 'Accept': 'application/vnd.github+json'})\n","        files = json.loads(response.text)['files']\n","        if len(files) == 100:\n","          while len(files) % 100 == 0:\n","            page += 1\n","            response = requests.get(f'{github_api_url}/commits/{s}?per_page=100&page={page}', headers = {'Authorization': f'Bearer {pat}', 'Accept': 'application/vnd.github+json'})\n","            files += json.loads(response.text)['files']\n","        raw_files += [{'sha': s, 'files': files}]\n","\n","      # parse data for files and combine with commit data in dataframe\n","      commits_files = []\n","      for c in raw_files:\n","        for f in c['files']:\n","          commits_files += [{\n","              'sha': c['sha'],\n","              'file_sha': f['sha'],\n","              'file': f\"{github_user}/{github_repo}/{f['filename']}\",\n","              'additions': f['additions'],\n","              'deletions': f['deletions']\n","          }]\n","      commits_files = pd.DataFrame(commits_files)\n","      commits_files = pd.merge(new_commits, commits_files, on = 'sha', how = 'inner')\n","\n","      # append files for new commits to BigQuery table\n","      new_commits_files_job = bq.load_table_from_dataframe(\n","          dataframe = commits_files,\n","          destination = bigquery.TableReference.from_string(f\"{BQ_PROJECT}.{BQ_DATASET}.commits_files\"),\n","          job_config = bigquery.LoadJobConfig(\n","              write_disposition = 'WRITE_APPEND', # WRITE_TRUNCATE = replace if exists, WRITE_APPEND = append if exists, WRITE_EMPTY = write new but dont overwrite\n","              autodetect = True, # detect schema\n","          )\n","      )\n","      new_commits_files_job.result()\n","\n","    # START: Content from notebook: GitHub Metrics - 2 - Commits\n","\n","    # update reporting tables (this was a BQ Scheduled Query)\n","    query = f\"\"\"\n","      INSERT INTO `vertex-ai-mlops-369716.reporting.commits_files`\n","        WITH\n","          CURRENT_COMMITS AS (SELECT sha FROM `vertex-ai-mlops-369716.reporting.commits`),\n","          SOURCE_COMMITS AS (SELECT sha FROM `vertex-ai-mlops-369716.github_metrics.commits`),\n","          NEW_COMMITS AS (SELECT SOURCE_COMMITS.sha FROM SOURCE_COMMITS WHERE NOT EXISTS (SELECT CURRENT_COMMITS.sha FROM CURRENT_COMMITS WHERE SOURCE_COMMITS.sha = CURRENT_COMMITS.sha)),\n","          RAW_COMMITS AS (SELECT * FROM NEW_COMMITS LEFT OUTER JOIN `vertex-ai-mlops-369716.github_metrics.commits_files` USING(sha))\n","        SELECT\n","          * EXCEPT(datetime),\n","          DATETIME(TIMESTAMP(datetime)) AS datetime\n","        FROM RAW_COMMITS\n","        ORDER BY datetime\n","      ;\n","      INSERT INTO `vertex-ai-mlops-369716.reporting.commits`\n","        WITH\n","          CURRENT_COMMITS AS (SELECT sha FROM `vertex-ai-mlops-369716.reporting.commits`),\n","          SOURCE_COMMITS AS (SELECT sha FROM `vertex-ai-mlops-369716.github_metrics.commits`),\n","          NEW_COMMITS AS (SELECT SOURCE_COMMITS.sha FROM SOURCE_COMMITS WHERE NOT EXISTS (SELECT CURRENT_COMMITS.sha FROM CURRENT_COMMITS WHERE SOURCE_COMMITS.sha = CURRENT_COMMITS.sha)),\n","          RAW_COMMITS AS (SELECT * FROM NEW_COMMITS LEFT OUTER JOIN `vertex-ai-mlops-369716.github_metrics.commits` USING(sha))\n","        SELECT\n","          * EXCEPT(datetime),\n","          DATETIME(TIMESTAMP(datetime)) AS datetime\n","        FROM RAW_COMMITS\n","        ORDER BY datetime\n","      ;\n","    \"\"\"\n","    job = bq.query(query = query)\n","    job.result()\n","    print(job.state)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":224,"status":"ok","timestamp":1677586576376,"user":{"displayName":"Mike Henderson","userId":"11664017018095232389"},"user_tz":300},"id":"XKMFg981bFFE","outputId":"edbba496-cb60-4461-d442-4ee8eb3594f4"},"outputs":[{"output_type":"stream","name":"stdout","text":["main.py  requirements.txt\n"]}],"source":["!ls {DIR}/function"]},{"cell_type":"markdown","metadata":{"id":"9AoZW8nLhQGW"},"source":["### Zip Files"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0gWHs48VbFCp"},"outputs":[],"source":["import zipfile\n","with zipfile.ZipFile(f'{DIR}/function/function_commit.zip', mode = 'w') as archive:\n","    archive.write(f'{DIR}/function/main.py', 'main.py')\n","    archive.write(f'{DIR}/function/requirements.txt', 'requirements.txt')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":228,"status":"ok","timestamp":1677586579422,"user":{"displayName":"Mike Henderson","userId":"11664017018095232389"},"user_tz":300},"id":"Z7159ULTbFBA","outputId":"66d2a61b-c2d3-4634-c8a8-891fb1bb2581"},"outputs":[{"output_type":"stream","name":"stdout","text":["function_commit.zip  main.py  requirements.txt\n"]}],"source":["!ls {DIR}/function"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":116,"status":"ok","timestamp":1677586580332,"user":{"displayName":"Mike Henderson","userId":"11664017018095232389"},"user_tz":300},"id":"TFsp0r0PbE-B","outputId":"e1f2a4c2-183a-40ee-bb83-8ae87829b84a"},"outputs":[{"output_type":"stream","name":"stdout","text":["File Name                                             Modified             Size\n","main.py                                        2023-02-28 12:16:14         7082\n","requirements.txt                               2023-02-28 12:16:12           60\n"]}],"source":["with zipfile.ZipFile(f'{DIR}/function/function_commit.zip', mode = 'r') as zip:\n","    zip.printdir()"]},{"cell_type":"markdown","metadata":{"id":"iioImcxihT5S"},"source":["### Move Files to GCS\n","\n","Expects a bucket with the same name as the project:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8K7w_jQ1bE6n"},"outputs":[],"source":["bucket = gcs.bucket(PROJECT_ID)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FAWndgwxlyVd"},"outputs":[],"source":["SOURCEPATH = f'architectures/tracking/setup/github'\n","blob = bucket.blob(f'{SOURCEPATH}/function_commit.zip')\n","blob.upload_from_filename(f'{DIR}/function/function_commit.zip')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":114,"status":"ok","timestamp":1677586597133,"user":{"displayName":"Mike Henderson","userId":"11664017018095232389"},"user_tz":300},"id":"V9KkgKA6lzkE","outputId":"d48d4c78-7f05-4786-dfad-7032da02d3dd"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<Blob: vertex-ai-mlops-369716, architectures/tracking/setup/github/function_commit.zip, 1677586594050541>]"]},"metadata":{},"execution_count":29}],"source":["list(bucket.list_blobs(prefix = f'{SOURCEPATH}'))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":133,"status":"ok","timestamp":1677586599472,"user":{"displayName":"Mike Henderson","userId":"11664017018095232389"},"user_tz":300},"id":"ZSLvyEQdlzhh","outputId":"d7cf8b82-3b8c-46d4-f308-a3de99a84806"},"outputs":[{"output_type":"stream","name":"stdout","text":["View the bucket directly here:\n","https://console.cloud.google.com/storage/browser/vertex-ai-mlops-369716/architectures/tracking/setup/github;tab=objects&project=vertex-ai-mlops-369716\n"]}],"source":["print(f\"View the bucket directly here:\\nhttps://console.cloud.google.com/storage/browser/{PROJECT_ID}/{SOURCEPATH};tab=objects&project={PROJECT_ID}\")"]},{"cell_type":"markdown","metadata":{"id":"VF7cLwtSvrQw"},"source":["### Service Account\n","The Cloud Function will run as a service account.  Retrieve the default app engine service account and check its permissions.  It needs to be able to read/write to BigQuery and read secrets from the secret manager.\n","\n","I used the Console to create a service account for these jobs:\n","- Console > IAM > Service Accounts\n","- Create New: name = `metrics-runner`\n","- roles = BigQuery Admin, Secret Accessor\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1677586601735,"user":{"displayName":"Mike Henderson","userId":"11664017018095232389"},"user_tz":300},"id":"KmzXT6wa6rNJ","outputId":"b8f512f8-b496-4fb1-ac4c-dc31681b3d79"},"outputs":[{"output_type":"stream","name":"stdout","text":["Review Service Account Details in Console:\n","https://console.cloud.google.com/iam-admin/serviceaccounts?project=vertex-ai-mlops-369716\n"]}],"source":["print(f'Review Service Account Details in Console:\\nhttps://console.cloud.google.com/iam-admin/serviceaccounts?project={PROJECT_ID}')"]},{"cell_type":"markdown","metadata":{"id":"38-1ERqwmyUZ"},"source":["### Create (or Update) Cloud Function"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"olE04Uw0lzfw"},"outputs":[],"source":["function_name = f'github_metrics_commits'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lCPBjqQwlzdN"},"outputs":[],"source":["function = ''\n","for function in functions_client.list_functions(request = functions_v1.ListFunctionsRequest(parent = f'projects/{PROJECT_ID}/locations/{REGION}')):\n","    if function.name.endswith(function_name):\n","        break\n","    else: function = ''"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":119,"status":"ok","timestamp":1677586606519,"user":{"displayName":"Mike Henderson","userId":"11664017018095232389"},"user_tz":300},"id":"Hdjvp8HLnC8d","outputId":"c3688943-9918-4b49-8cfd-338dfdd90fe5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["name: \"projects/vertex-ai-mlops-369716/locations/us-central1/functions/github_metrics_commits\"\n","source_archive_url: \"gs://vertex-ai-mlops-369716/architectures/tracking/setup/github/function_commit.zip\"\n","event_trigger {\n","  event_type: \"providers/cloud.pubsub/eventTypes/topic.publish\"\n","  resource: \"projects/vertex-ai-mlops-369716/topics/daily_metrics_triggers\"\n","  service: \"pubsub.googleapis.com\"\n","  failure_policy {\n","  }\n","}\n","status: ACTIVE\n","entry_point: \"collect\"\n","timeout {\n","  seconds: 420\n","}\n","available_memory_mb: 256\n","service_account_email: \"metrics-runner@vertex-ai-mlops-369716.iam.gserviceaccount.com\"\n","update_time {\n","  seconds: 1676847212\n","  nanos: 97000000\n","}\n","version_id: 5\n","runtime: \"python310\"\n","max_instances: 3000\n","ingress_settings: ALLOW_ALL\n","build_id: \"0354f03f-c84c-497c-8ed3-5631cce37f1e\"\n","secret_environment_variables {\n","  key: \"GITHUB_PAT\"\n","  project_id: \"807305962454\"\n","  secret: \"github_api\"\n","  version: \"latest\"\n","}\n","build_name: \"projects/807305962454/locations/us-central1/builds/0354f03f-c84c-497c-8ed3-5631cce37f1e\"\n","docker_registry: CONTAINER_REGISTRY"]},"metadata":{},"execution_count":34}],"source":["function"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c9e88xwClzbV"},"outputs":[],"source":["from google.protobuf.duration_pb2 import Duration\n","\n","functionDef = functions_v1.CloudFunction()\n","functionDef.name = f'projects/{PROJECT_ID}/locations/{REGION}/functions/{function_name}'\n","functionDef.source_archive_url = f\"gs://{PROJECT_ID}/{SOURCEPATH}/function_commit.zip\"\n","functionDef.event_trigger = functions_v1.EventTrigger()\n","functionDef.event_trigger.event_type = 'providers/cloud.pubsub/eventTypes/topic.publish'\n","functionDef.event_trigger.resource = topic.name\n","functionDef.runtime = 'python310'\n","functionDef.entry_point = 'collect'\n","functionDef.timeout = Duration(seconds = 420)\n","functionDef.service_account_email = f\"metrics-runner@{PROJECT_ID}.iam.gserviceaccount.com\"\n","functionDef.secret_environment_variables = [functions_v1.SecretEnvVar(\n","    key = 'GITHUB_PAT',\n","    secret = 'github_api'\n",")]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":112,"status":"ok","timestamp":1677586611128,"user":{"displayName":"Mike Henderson","userId":"11664017018095232389"},"user_tz":300},"id":"VkQ9l8AYlzY9","outputId":"aeb7a0e9-dbe4-4a3e-bc97-1f2ad677c9c4"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["name: \"projects/vertex-ai-mlops-369716/locations/us-central1/functions/github_metrics_commits\"\n","source_archive_url: \"gs://vertex-ai-mlops-369716/architectures/tracking/setup/github/function_commit.zip\"\n","event_trigger {\n","  event_type: \"providers/cloud.pubsub/eventTypes/topic.publish\"\n","  resource: \"projects/vertex-ai-mlops-369716/topics/daily_metrics_triggers\"\n","}\n","entry_point: \"collect\"\n","timeout {\n","  seconds: 420\n","}\n","service_account_email: \"metrics-runner@vertex-ai-mlops-369716.iam.gserviceaccount.com\"\n","runtime: \"python310\"\n","secret_environment_variables {\n","  key: \"GITHUB_PAT\"\n","  secret: \"github_api\"\n","}"]},"metadata":{},"execution_count":36}],"source":["functionDef"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OomTBZM-lzWP"},"outputs":[],"source":["if function:\n","    request = functions_v1.UpdateFunctionRequest(\n","        function = functionDef\n","    )\n","    operation = functions_client.update_function(request = request)\n","else:\n","    request = functions_v1.CreateFunctionRequest(\n","        location = f\"projects/{PROJECT_ID}/locations/{REGION}\",\n","        function = functionDef\n","    )\n","    operation = functions_client.create_function(request = request)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":146694,"status":"ok","timestamp":1677586762157,"user":{"displayName":"Mike Henderson","userId":"11664017018095232389"},"user_tz":300},"id":"aFeoweDQlzS5","outputId":"bb422c2f-3615-422d-96c6-a1c79cd4eda1"},"outputs":[{"output_type":"stream","name":"stdout","text":["name: \"projects/vertex-ai-mlops-369716/locations/us-central1/functions/github_metrics_commits\"\n","source_archive_url: \"gs://vertex-ai-mlops-369716/architectures/tracking/setup/github/function_commit.zip\"\n","event_trigger {\n","  event_type: \"providers/cloud.pubsub/eventTypes/topic.publish\"\n","  resource: \"projects/vertex-ai-mlops-369716/topics/daily_metrics_triggers\"\n","  service: \"pubsub.googleapis.com\"\n","  failure_policy {\n","  }\n","}\n","status: ACTIVE\n","entry_point: \"collect\"\n","timeout {\n","  seconds: 420\n","}\n","available_memory_mb: 256\n","service_account_email: \"metrics-runner@vertex-ai-mlops-369716.iam.gserviceaccount.com\"\n","update_time {\n","  seconds: 1677586751\n","  nanos: 693000000\n","}\n","version_id: 6\n","runtime: \"python310\"\n","max_instances: 3000\n","ingress_settings: ALLOW_ALL\n","build_id: \"c24d64d5-c363-4e84-9b3a-03e016cd363e\"\n","secret_environment_variables {\n","  key: \"GITHUB_PAT\"\n","  project_id: \"807305962454\"\n","  secret: \"github_api\"\n","  version: \"latest\"\n","}\n","build_name: \"projects/807305962454/locations/us-central1/builds/c24d64d5-c363-4e84-9b3a-03e016cd363e\"\n","docker_registry: CONTAINER_REGISTRY\n","\n"]}],"source":["response = operation.result()\n","print(response)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1677586762158,"user":{"displayName":"Mike Henderson","userId":"11664017018095232389"},"user_tz":300},"id":"pYRzg_23lzQg","outputId":"517fc07d-c0f6-4c5d-b2b9-d970ee4dce55"},"outputs":[{"output_type":"stream","name":"stdout","text":["Review the Cloud Function in the console here:\n","https://console.cloud.google.com/functions/list?env=gen1&project=vertex-ai-mlops-369716\n"]}],"source":["print(f'Review the Cloud Function in the console here:\\nhttps://console.cloud.google.com/functions/list?env=gen1&project={PROJECT_ID}')"]},{"cell_type":"markdown","metadata":{"id":"09eF9DPCqPDF"},"source":["### Manual Run of Cloud Function\n","\n","Publish a message to the Pub/Sub topic that will cause the Cloud Function to initiate training.  The code below could be anywhere you want to trigger training!\n","\n","The function will receive the message as `event` in the format:\n","```\n","{\n","    '@type': 'type.googleapis.com/google.pubsub.v1.PubsubMessage',\n","    'attributes': {'key' : 'value', ...},\n","    'data': <base64 encoded string>\n","}\n","```\n","\n","To handle the `event` and retrieve the inputs of the message three things need to happen:\n","1. reference the 'data' value as `event['data']`\n","2. decode the 'data' value with `base64.b64decode(<1>).decode('utf-8')`\n","3. convert the decoded string into a Python dictionary with `json.loads(<2>)`\n","\n","This looks like:\n","```\n","funtion_inputs = json.loads(base64.b64decode(event['data']).decode('utf-8'))\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YLvUdDCUlzNa"},"outputs":[],"source":["function_input = {\n","    'PROJECT_ID': PROJECT_ID\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NRiUp32ElzKk"},"outputs":[],"source":["message = json.dumps(function_input)\n","message = message.encode('utf-8')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5iVY4blUnLJy"},"outputs":[],"source":["future = pubsub_pubclient.publish(topic.name, message, trigger = 'manual')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":136,"status":"ok","timestamp":1677586835738,"user":{"displayName":"Mike Henderson","userId":"11664017018095232389"},"user_tz":300},"id":"g0El69aJnLGc","outputId":"8a3842bc-d378-4d2d-e855-c096726fc6ac"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'7043211265006086'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":43}],"source":["future.result()"]},{"cell_type":"markdown","metadata":{"id":"sIldXzPpqftI"},"source":["---\n","## Scheduled Run with Cloud Scheduler\n","\n","Use Cloud Scheduler to publish a message to the topic at any defined interval which will cause the Cloud Function to initiate training.\n","\n","Resources:\n","- List of Time zones - [TZ Database Names](https://en.wikipedia.org/wiki/List_of_tz_database_time_zones)\n","- Job Frequency - [unix-cron format guide](https://man7.org/linux/man-pages/man5/crontab.5.html)\n","    - minute hour day_of_month month day_of_week\n","    - 0 23 * * tue = 11PM every Tuesday\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j5E3Is9hnLCV"},"outputs":[],"source":["schedule_name = 'daily_3am_est'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BKdJXugMnLAE"},"outputs":[],"source":["schedule = ''\n","for schedule in scheduler_client.list_jobs(parent = f'projects/{PROJECT_ID}/locations/{REGION}'):\n","    if schedule.name.endswith(schedule_name):\n","        break\n","    else: schedule = ''"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":796,"status":"ok","timestamp":1676847544527,"user":{"displayName":"Mike Henderson","userId":"11664017018095232389"},"user_tz":300},"id":"LCc7ponWnK-F","outputId":"8657384d-5904-46ac-cd66-50ea47937444"},"outputs":[{"name":"stdout","output_type":"stream","text":["name: \"projects/vertex-ai-mlops-369716/locations/us-central1/jobs/daily_3am_est\"\n","pubsub_target {\n","  topic_name: \"projects/vertex-ai-mlops-369716/topics/daily_metrics_triggers\"\n","  data: \"{\\\"PROJECT_ID\\\": \\\"vertex-ai-mlops-369716\\\"}\"\n","  attributes {\n","    key: \"trigger\"\n","    value: \"scheduled\"\n","  }\n","}\n","user_update_time {\n","  seconds: 1676847544\n","}\n","state: ENABLED\n","schedule: \"0 3 * * *\"\n","time_zone: \"America/New_York\"\n","\n"]}],"source":["if schedule:\n","    print(schedule)\n","else:\n","    request = scheduler_v1.CreateJobRequest(\n","        parent = f'projects/{PROJECT_ID}/locations/{REGION}',\n","        job = scheduler_v1.Job(\n","            name = f'projects/{PROJECT_ID}/locations/{REGION}/jobs/{schedule_name}',\n","            pubsub_target = scheduler_v1.PubsubTarget(\n","                topic_name = topic.name,\n","                data = message,\n","                attributes = {'trigger': 'scheduled'}\n","            ),\n","            schedule = '0 3 * * *',\n","            time_zone = 'America/New_York'\n","        )\n","    )\n","    schedule = scheduler_client.create_job(request = request)\n","    print(schedule)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1676847992379,"user":{"displayName":"Mike Henderson","userId":"11664017018095232389"},"user_tz":300},"id":"-OlK0diknK7q","outputId":"cb418f87-d711-4ae7-ab85-ae19fd1e3d02"},"outputs":[{"name":"stdout","output_type":"stream","text":["Review the schedule in the console:\n","https://console.cloud.google.com/cloudscheduler?project=vertex-ai-mlops-369716\n"]}],"source":["print(f'Review the schedule in the console:\\nhttps://console.cloud.google.com/cloudscheduler?project={PROJECT_ID}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CS_HXRUanK5d"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ASmMNNQvnK2k"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VwI00glLnKz8"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[],"toc_visible":true},"environment":{"kernel":"python3","name":"tf2-gpu.2-3.m94","type":"gcloud","uri":"gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m94"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":0}