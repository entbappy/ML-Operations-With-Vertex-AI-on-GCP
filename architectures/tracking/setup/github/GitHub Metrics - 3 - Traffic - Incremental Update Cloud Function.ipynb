{"cells":[{"cell_type":"markdown","metadata":{"id":"vc7wbgTVhZfL"},"source":["![ga4](https://www.google-analytics.com/collect?v=2&tid=G-6VDTYWLKX6&cid=1&en=page_view&sid=1&dl=statmike%2Fvertex-ai-mlops%2Farchitectures%2Ftracking%2Fsetup%2Fgithub&dt=GitHub+Metrics+-+3+-+Traffic+-+Incremental+Update+Cloud+Function.ipynb)\n","\n","# GitHub Metrics: Traffic History Cloud Function For Incremental Updates\n","\n","The notebooks for traffic history in steps 1 and 2 created and initial setup of tables in the BigQuery datasets `github_metrics` and `reporting`.  Tables are named the same within both.  The logic for incrementally updating these is also tested and developed in those notebooks.\n","\n","**Tables**\n","- `traffic_clones`\n","- `traffic_popular_paths`\n","- `traffic_popular_referrers`\n","- `traffic_views`\n","- `stargazers`\n","- `forks`\n","- `subscribers`\n","\n","\n","This notebook creates a Cloud Function to run the code that incrementally updates the tables in the datasets and schedules it to run daily using Pub/Sub and Cloud Scheduler.\n","\n","\n","**Notes**\n","- The Pub/Sub topic is shared between all step 3 notebooks\n","- The Cloud Scheduler is shared between all step 3 notebooks"]},{"cell_type":"markdown","metadata":{"id":"Nw1ZZWFyXw2L"},"source":["---\n","## Colab Setup\n","\n","To run this notebook in Colab click [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/statmike/vertex-ai-mlops/blob/main/architectures/tracking/setup/github/GitHub%20Metrics%20-%203%20-%20Traffic%20-%20Incremental%20Update%20Cloud%20Function.ipynb) and run the cells in this section.  Otherwise, skip this section.\n","\n","This cell will authenticate to GCP (follow prompts in the popup)."]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1677604283748,"user":{"displayName":"Mike Henderson","userId":"11664017018095232389"},"user_tz":300},"id":"MWl8BI5apkcI"},"outputs":[],"source":["PROJECT_ID = 'vertex-ai-mlops-369716' # replace with project ID"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24018,"status":"ok","timestamp":1677604307760,"user":{"displayName":"Mike Henderson","userId":"11664017018095232389"},"user_tz":300},"id":"WdZkhxNLoVNY","outputId":"d113c1b7-4e70-42b8-e12b-0787e10bc8be"},"outputs":[{"output_type":"stream","name":"stdout","text":["Updated property [core/project].\n"]}],"source":["try:\n","    import google.colab\n","    from google.colab import auth\n","    auth.authenticate_user()\n","    !gcloud config set project {PROJECT_ID}\n","except Exception:\n","    pass"]},{"cell_type":"markdown","metadata":{"id":"_-QlhG8rZDvT"},"source":["---\n","## Package Installs (if needed)\n","\n","This notebook uses the Python Clients for\n","- Google Service Usage\n","    - to enable APIs\n","- Cloud Pub/Sub\n","- Cloud Functions\n","- Cloud Scheduler\n","\n","The cells below check to see if the required Python libraries are installed.  If any are not it will print a message to do the install with the associated pip command to use.  These installs must be completed before continuing this notebook."]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19790,"status":"ok","timestamp":1677604346554,"user":{"displayName":"Mike Henderson","userId":"11664017018095232389"},"user_tz":300},"id":"HP8pLhQMZEMe","outputId":"b4b4041f-d382-44db-dd8e-a22a7bfbcdc2"},"outputs":[{"output_type":"stream","name":"stdout","text":["You need to pip install google-cloud-service-usage\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 KB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hYou need to pip install google-cloud-pubsub\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.0/243.0 KB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hYou need to pip install google-cloud-functions\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.6/125.6 KB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hYou need to pip install google-cloud-scheduler\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.5/98.5 KB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["try:\n","    import google.cloud.service_usage_v1\n","except ImportError:\n","    print('You need to pip install google-cloud-service-usage')\n","    !pip install google-cloud-service-usage -q\n","\n","try:\n","    import google.cloud.pubsub\n","except ImportError:\n","    print('You need to pip install google-cloud-pubsub')\n","    !pip install google-cloud-pubsub -q\n","\n","try:\n","    import google.cloud.functions\n","except ImportError:\n","    print('You need to pip install google-cloud-functions')\n","    !pip install google-cloud-functions -q\n","\n","try:\n","    import google.cloud.scheduler\n","except ImportError:\n","    print('You need to pip install google-cloud-scheduler')\n","    !pip install google-cloud-scheduler -q"]},{"cell_type":"markdown","metadata":{"id":"tVA5SciOoNlf"},"source":["---\n","## Setup"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":1019,"status":"ok","timestamp":1677604347567,"user":{"displayName":"Mike Henderson","userId":"11664017018095232389"},"user_tz":300},"id":"pCPIhNOomdyi","outputId":"6b003728-7790-4343-e8ce-19f2ff1ffac1"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'vertex-ai-mlops-369716'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":4}],"source":["project = !gcloud config get-value project\n","PROJECT_ID = project[0]\n","PROJECT_ID"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1677604347568,"user":{"displayName":"Mike Henderson","userId":"11664017018095232389"},"user_tz":300},"id":"JwYJTkWAoY5U"},"outputs":[],"source":["REGION = 'us-central1'\n","\n","github_user = 'statmike'\n","github_repo = 'vertex-ai-mlops'\n","\n","BQ_PROJECT = PROJECT_ID\n","BQ_DATASET = 'github_metrics'"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":2098,"status":"ok","timestamp":1677604352083,"user":{"displayName":"Mike Henderson","userId":"11664017018095232389"},"user_tz":300},"id":"wjIPLHPWoY8O"},"outputs":[],"source":["import requests\n","import json\n","import time\n","from datetime import datetime\n","import pandas as pd\n","from io import StringIO\n","import os, shutil\n","\n","from google.cloud import bigquery\n","from google.cloud import storage\n","\n","from google.cloud import service_usage_v1\n","from google.cloud import pubsub_v1\n","from google.cloud import functions_v1\n","from google.cloud import scheduler_v1"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":956,"status":"ok","timestamp":1677604354275,"user":{"displayName":"Mike Henderson","userId":"11664017018095232389"},"user_tz":300},"id":"YyZ2WKRtoY-R"},"outputs":[],"source":["bq = bigquery.Client(project = PROJECT_ID)\n","gcs = storage.Client(project = PROJECT_ID)\n","\n","su_client = service_usage_v1.ServiceUsageClient()\n","pubsub_pubclient = pubsub_v1.PublisherClient() \n","functions_client = functions_v1.CloudFunctionsServiceClient()\n","scheduler_client = scheduler_v1.CloudSchedulerClient()"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":655,"status":"ok","timestamp":1677604356108,"user":{"displayName":"Mike Henderson","userId":"11664017018095232389"},"user_tz":300},"id":"4Uy3ZhfdglKE"},"outputs":[],"source":["DIR = 'temp'\n","!rm -rf {DIR}\n","!mkdir -p {DIR}"]},{"cell_type":"markdown","metadata":{"id":"_LnkZxK8b_Rx"},"source":["---\n","## Enable APIs\n","\n","Using Cloud Functions, Cloud Pub/Sub and Cloud Scheduler requires enabling these APIs for the Google Cloud Project.  Additionally, Cloud Functions uses Cloud Build which also need to be enabled.\n","\n","Options for enabeling these.  In this notebook option 2 is used.\n"," 1. Use the APIs & Services page in the console: https://console.cloud.google.com/apis\n","     - `+ Enable APIs and Services`\n","     - Search for Cloud Build and Enable\n","     - Search for Artifact Registry and Enable\n"," 2. Use [Google Service Usage](https://cloud.google.com/service-usage/docs) API from Python\n","     - [Python Client For Service Usage](https://github.com/googleapis/python-service-usage)\n","     - [Python Client Library Documentation](https://cloud.google.com/python/docs/reference/serviceusage/latest)\n","     \n","The following code cells use the Service Usage Client to:\n","- get the state of the service\n","- if 'DISABLED':\n","    - Try enabling the service and return the state after trying\n","- if 'ENABLED' print the state for confirmation"]},{"cell_type":"markdown","metadata":{"id":"5s4qC8wKxy7y"},"source":["### IAM\n","The API may be needed for creating a service account to run the Cloud Function"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":537,"status":"ok","timestamp":1677604361535,"user":{"displayName":"Mike Henderson","userId":"11664017018095232389"},"user_tz":300},"id":"qJstNPsVxzU3","outputId":"4210afee-91aa-4b10-9d7d-a98bc4c78159"},"outputs":[{"output_type":"stream","name":"stdout","text":["IAM already enabled for project: vertex-ai-mlops-369716\n"]}],"source":["iam = su_client.get_service(\n","    request = service_usage_v1.GetServiceRequest(\n","        name = f'projects/{PROJECT_ID}/services/iam.googleapis.com'\n","    )\n",").state.name\n","\n","\n","if iam == 'DISABLED':\n","    print(f'IAM is currently {iam} for project: {PROJECT_ID}')\n","    print(f'Trying to Enable...')\n","    operation = su_client.enable_service(\n","        request = service_usage_v1.EnableServiceRequest(\n","            name = f'projects/{PROJECT_ID}/services/iam.googleapis.com'\n","        )\n","    )\n","    response = operation.result()\n","    if response.service.state.name == 'ENABLED':\n","        print(f'IAM is now enabled for project: {PROJECT_ID}')\n","    else:\n","        print(response)\n","else:\n","    print(f'IAM already enabled for project: {PROJECT_ID}')"]},{"cell_type":"markdown","metadata":{"id":"1dwUhJJ2cKHc"},"source":["### Cloud Pub/Sub"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":717,"status":"ok","timestamp":1677604365498,"user":{"displayName":"Mike Henderson","userId":"11664017018095232389"},"user_tz":300},"id":"sT8dJC1JcKqQ","outputId":"b63506b3-b789-4690-e7a6-9b05623d7426"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloud Pub/Sub already enabled for project: vertex-ai-mlops-369716\n"]}],"source":["pubsub = su_client.get_service(\n","    request = service_usage_v1.GetServiceRequest(\n","        name = f'projects/{PROJECT_ID}/services/pubsub.googleapis.com'\n","    )\n",").state.name\n","\n","\n","if pubsub == 'DISABLED':\n","    print(f'Cloud Pub/Sub is currently {pubsub} for project: {PROJECT_ID}')\n","    print(f'Trying to Enable...')\n","    operation = su_client.enable_service(\n","        request = service_usage_v1.EnableServiceRequest(\n","            name = f'projects/{PROJECT_ID}/services/pubsub.googleapis.com'\n","        )\n","    )\n","    response = operation.result()\n","    if response.service.state.name == 'ENABLED':\n","        print(f'Cloud Pub/Sub is now enabled for project: {PROJECT_ID}')\n","    else:\n","        print(response)\n","else:\n","    print(f'Cloud Pub/Sub already enabled for project: {PROJECT_ID}')"]},{"cell_type":"markdown","metadata":{"id":"S3JwTpSLcLD8"},"source":["### Cloud Functions"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":163,"status":"ok","timestamp":1677604366754,"user":{"displayName":"Mike Henderson","userId":"11664017018095232389"},"user_tz":300},"id":"6IMhH26acLj6","outputId":"fde6a853-cac7-4ec1-e620-43fc02a6ca14"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloud Functions already enabled for project: vertex-ai-mlops-369716\n"]}],"source":["cloudfunctions = su_client.get_service(\n","    request = service_usage_v1.GetServiceRequest(\n","        name = f'projects/{PROJECT_ID}/services/cloudfunctions.googleapis.com'\n","    )\n",").state.name\n","\n","\n","if cloudfunctions == 'DISABLED':\n","    print(f'Cloud Functions is currently {cloudfunctions} for project: {PROJECT_ID}')\n","    print(f'Trying to Enable...')\n","    operation = su_client.enable_service(\n","        request = service_usage_v1.EnableServiceRequest(\n","            name = f'projects/{PROJECT_ID}/services/cloudfunctions.googleapis.com'\n","        )\n","    )\n","    response = operation.result()\n","    if response.service.state.name == 'ENABLED':\n","        print(f'Cloud Functions is now enabled for project: {PROJECT_ID}')\n","    else:\n","        print(response)\n","else:\n","    print(f'Cloud Functions already enabled for project: {PROJECT_ID}')"]},{"cell_type":"markdown","metadata":{"id":"F3NMT-u2cL8o"},"source":["### Cloud Scheduler"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":309,"status":"ok","timestamp":1677604368267,"user":{"displayName":"Mike Henderson","userId":"11664017018095232389"},"user_tz":300},"id":"WV5-Tl8CcMah","outputId":"fb19f286-bf4b-4b63-826a-6c5f2733b1f0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloud Scheduler already enabled for project: vertex-ai-mlops-369716\n"]}],"source":["cloudscheduler = su_client.get_service(\n","    request = service_usage_v1.GetServiceRequest(\n","        name = f'projects/{PROJECT_ID}/services/cloudscheduler.googleapis.com'\n","    )\n",").state.name\n","\n","\n","if cloudscheduler == 'DISABLED':\n","    print(f'Cloud Scheduler is currently {cloudscheduler} for project: {PROJECT_ID}')\n","    print(f'Trying to Enable...')\n","    operation = su_client.enable_service(\n","        request = service_usage_v1.EnableServiceRequest(\n","            name = f'projects/{PROJECT_ID}/services/cloudscheduler.googleapis.com'\n","        )\n","    )\n","    response = operation.result()\n","    if response.service.state.name == 'ENABLED':\n","        print(f'Cloud Scheduler is now enabled for project: {PROJECT_ID}')\n","    else:\n","        print(response)\n","else:\n","    print(f'Cloud Scheduler already enabled for project: {PROJECT_ID}')"]},{"cell_type":"markdown","metadata":{"id":"uXkO3We2opgE"},"source":["### Cloud Build \n","Used By Cloud Functions"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":391,"status":"ok","timestamp":1677604369961,"user":{"displayName":"Mike Henderson","userId":"11664017018095232389"},"user_tz":300},"id":"cKNT0f1qop8s","outputId":"6ba641e0-54c6-48c0-a14a-5467b783c0bc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloud Build already enabled for project: vertex-ai-mlops-369716\n"]}],"source":["cloudbuild = su_client.get_service(\n","    request = service_usage_v1.GetServiceRequest(\n","        name = f'projects/{PROJECT_ID}/services/cloudbuild.googleapis.com'\n","    )\n",").state.name\n","\n","\n","if cloudbuild == 'DISABLED':\n","    print(f'Cloud Build is currently {cloudbuild} for project: {PROJECT_ID}')\n","    print(f'Trying to Enable...')\n","    operation = su_client.enable_service(\n","        request = service_usage_v1.EnableServiceRequest(\n","            name = f'projects/{PROJECT_ID}/services/cloudbuild.googleapis.com'\n","        )\n","    )\n","    response = operation.result()\n","    if response.service.state.name == 'ENABLED':\n","        print(f'Cloud Build is now enabled for project: {PROJECT_ID}')\n","    else:\n","        print(response)\n","else:\n","    print(f'Cloud Build already enabled for project: {PROJECT_ID}')"]},{"cell_type":"markdown","metadata":{"id":"R8C45WQpaHIB"},"source":["---\n","## Pub/Sub\n","Use a Pub/Sub topic to trigger a Cloud Function to run.  The topic will be able to receive message manually or on a schedule from Cloud Scheduler.\n","\n","The main concepts:\n","- Topic - a feed of messages\n","     - Publish - send a new message to a topic\n","     - Subscription - receive messages that arrive on topic\n","          - Push - the subscriber has new messages pushed to it\n","          - Pull - the subscriber request new messages by pulling them\n","          \n","In this example, a topic will be set up for daily runs of metric functions.  Publishing a new message to this topic will trigger one or more Cloud Functions to run like the one setup below.  The Cloud Funtion will have a push subscription to the topic."]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":124,"status":"ok","timestamp":1677604373218,"user":{"displayName":"Mike Henderson","userId":"11664017018095232389"},"user_tz":300},"id":"oieCXgTJaBzf"},"outputs":[],"source":["PUBSUB_TOPIC = 'daily_metrics_triggers'"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":298,"status":"ok","timestamp":1677604374715,"user":{"displayName":"Mike Henderson","userId":"11664017018095232389"},"user_tz":300},"id":"73xvkrPAbFVI"},"outputs":[],"source":["topic = ''\n","for topic in pubsub_pubclient.list_topics(project = f'projects/{PROJECT_ID}'):\n","    if topic.name.endswith(PUBSUB_TOPIC):\n","        break\n","    else: topic = ''"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1677604376513,"user":{"displayName":"Mike Henderson","userId":"11664017018095232389"},"user_tz":300},"id":"UlsN_SjKbFSn","outputId":"298e3264-cb94-479d-e428-97ef7a11a5af"},"outputs":[{"output_type":"stream","name":"stdout","text":["name: \"projects/vertex-ai-mlops-369716/topics/daily_metrics_triggers\"\n","\n"]}],"source":["if topic:\n","    print(topic)\n","else:\n","    topic = pubsub_pubclient.create_topic(\n","        name = pubsub_pubclient.topic_path(PROJECT_ID, PUBSUB_TOPIC)\n","    )\n","    print(topic)"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":139,"status":"ok","timestamp":1677604377556,"user":{"displayName":"Mike Henderson","userId":"11664017018095232389"},"user_tz":300},"id":"xRoSIOtC7IQF","outputId":"d1779a67-a930-4db1-d19e-53c1ae7c2e56"},"outputs":[{"output_type":"stream","name":"stdout","text":["Review The Pub/Sub Topic In The Console:\n","https://console.cloud.google.com/cloudpubsub/topic/list?project=vertex-ai-mlops-369716\n"]}],"source":["print(f'Review The Pub/Sub Topic In The Console:\\nhttps://console.cloud.google.com/cloudpubsub/topic/list?project={PROJECT_ID}')"]},{"cell_type":"markdown","metadata":{"id":"kaK6itFkgF80"},"source":["---\n","## Cloud Function\n","\n","Create a Cloud Funtion that runs the incremental update code for the tables in the dataset `github_metrics`.  The method below creates code files and zips them for storage on Cloud Storage as a source to the Cloud Function."]},{"cell_type":"markdown","metadata":{"id":"Jew-vd3XggLq"},"source":["### Create Files"]},{"cell_type":"code","execution_count":67,"metadata":{"executionInfo":{"elapsed":642,"status":"ok","timestamp":1677608500142,"user":{"displayName":"Mike Henderson","userId":"11664017018095232389"},"user_tz":300},"id":"kpyBT84nbFPu"},"outputs":[],"source":["if os.path.exists(f'{DIR}/function'): shutil.rmtree(f'{DIR}/function')\n","os.makedirs(f'{DIR}/function')"]},{"cell_type":"code","execution_count":68,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1677608500143,"user":{"displayName":"Mike Henderson","userId":"11664017018095232389"},"user_tz":300},"id":"LrXx5dQPbFNA","outputId":"8c56c55e-c9b3-4ae5-ecc7-b9fe602a1001"},"outputs":[{"output_type":"stream","name":"stdout","text":["Writing temp/function/requirements.txt\n"]}],"source":["%%writefile {DIR}/function/requirements.txt\n","pandas\n","db-dtypes\n","google-cloud-bigquery"]},{"cell_type":"code","execution_count":69,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1677608500330,"user":{"displayName":"Mike Henderson","userId":"11664017018095232389"},"user_tz":300},"id":"KENNnOrbbFJV","outputId":"84de8aab-cc6e-4ff9-fc0f-7e6880bc18c5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Writing temp/function/main.py\n"]}],"source":["%%writefile {DIR}/function/main.py\n","\n","# packages\n","import base64\n","import requests\n","import json\n","from datetime import datetime\n","import pandas as pd\n","import numpy as np\n","import os\n","import urllib\n","from google.cloud import bigquery\n","\n","\n","# clients\n","bq = bigquery.Client()\n","\n","\n","# parameters\n","github_user = 'statmike'\n","github_repo = 'vertex-ai-mlops'\n","BQ_DATASET = 'github_metrics'\n","github_api_url = f'https://api.github.com/repos/{github_user}/{github_repo}'\n","pat = os.getenv('GITHUB_PAT')\n","\n","\n","# helper function\n","def metric_get(metric_type, query_parameters = ''):\n","  response = requests.get(f'{github_api_url}/{metric_type}{query_parameters}', headers = {'Authorization': f'Bearer {pat}', 'Accept': 'application/vnd.github+json'})\n","  while response.status_code == 202:\n","      time.sleep(10)\n","      response = requests.get(f'{github_api_url}/{metric_type}{query_parameters}', headers = {'Authorization': f'Bearer {pat}', 'Accept': 'application/vnd.github+json'})\n","  return response\n","\n","\n","# the function\n","def collect(event, context):\n","\n","    # print inputs to Cloud Function\n","    function_inputs = json.loads(base64.b64decode(event['data']).decode('utf-8'))\n","    print(function_inputs)\n","    PROJECT_ID = function_inputs['PROJECT_ID']\n","    BQ_PROJECT = PROJECT_ID\n","\n","    # START: Content from notebook: GitHub Metrics - 1 - Traffic\n","\n","    # traffic_clones\n","    query = f\"\"\"\n","    SELECT t.*\n","    FROM `{BQ_PROJECT}.{BQ_DATASET}.traffic_clones` t\n","    WHERE 1=1 QUALIFY row_number() OVER(ORDER BY timestamp DESC) = 1\n","    \"\"\"\n","    prior_traffic_clones = bq.query(query = query).to_dataframe()\n","    metric_type = 'traffic/clones'\n","    response = metric_get(metric_type)\n","    new_traffic_clones = pd.DataFrame(json.loads(response.text)['clones'])\n","    if new_traffic_clones['timestamp'].iloc[-1] != datetime.now().strftime(\"%Y-%m-%dT00:00:00Z\"):\n","      # gap, likely due to no clones on a day, insert today with uniques clones\n","      new_traffic_clones = new_traffic_clones.append({'timestamp': datetime.now().strftime(\"%Y-%m-%dT00:00:00Z\"), 'count': 0, 'uniques': 0}, ignore_index = True).sort_values(by = ['timestamp'])\n","    new_traffic_clones['uniques_last14days'] = np.nan\n","    new_traffic_clones['uniques_last14days'].iloc[-1] = json.loads(response.text)['uniques']\n","    new_traffic_clones['repo'] = github_user + '/' + github_repo\n","    overlap_record = new_traffic_clones[new_traffic_clones['timestamp'] == prior_traffic_clones['timestamp'].iloc[0]]\n","    new_records = new_traffic_clones[new_traffic_clones['timestamp'] > prior_traffic_clones['timestamp'].iloc[0]]\n","    if overlap_record.shape[0] == 1:\n","      if overlap_record[['timestamp', 'count', 'uniques']].values.tolist() != prior_traffic_clones[['timestamp', 'count', 'uniques']].values.tolist():\n","        updated_record = overlap_record\n","        updated_record['uniques_last14days'].iloc[0] = prior_traffic_clones['uniques_last14days'].iloc[0] \n","        new_records = pd.concat([updated_record, new_records], ignore_index = True, axis = 0)\n","        job = bq.query(query = f\"DELETE FROM `{BQ_PROJECT}.{BQ_DATASET}.traffic_clones` WHERE timestamp = '{updated_record['timestamp'].iloc[0]}'\")\n","        job.result()\n","    if new_records.shape[0] >=1:\n","      append_job = bq.load_table_from_dataframe(\n","            dataframe = new_records,\n","            destination = bigquery.TableReference.from_string(f\"{BQ_PROJECT}.{BQ_DATASET}.traffic_clones\"),\n","            job_config = bigquery.LoadJobConfig(\n","                write_disposition = 'WRITE_APPEND',\n","                autodetect = True, # detect schema\n","            ) \n","      )\n","      append_job.result()\n","\n","    # traffic_popular_paths\n","    metric_type = 'traffic/popular/paths'\n","    response = metric_get(metric_type)\n","    traffic_popular_paths = pd.DataFrame(json.loads(response.text))\n","    def parse_path(p):\n","        p = urllib.parse.unquote(p).replace('blob/main/', '')\n","        p = urllib.parse.unquote(p).replace('tree/main/', '')\n","        if p.rfind('.') == -1 or (p.rfind('.') < p.rfind('/')):\n","            p += '/readme.md'\n","        return p\n","    traffic_popular_paths['file'] = traffic_popular_paths.apply(lambda x: parse_path(x['path']), axis = 1)\n","    traffic_popular_paths = traffic_popular_paths.drop(['title', 'path'], axis = 1)\n","    traffic_popular_paths['timestamp'] = datetime.now().strftime(\"%Y-%m-%dT00:00:00Z\") #strftime(\"%Y-%m-%dT%H:%M:%SZ\") \n","    traffic_popular_paths['repo'] = github_user + '/' + github_repo\n","    query = f\"\"\"\n","    SELECT *\n","    FROM `{BQ_PROJECT}.{BQ_DATASET}.traffic_popular_paths`\n","    WHERE timestamp = '{traffic_popular_paths['timestamp'].max()}'\n","    ORDER BY count DESC\n","    \"\"\"\n","    prior = bq.query(query = query).to_dataframe()\n","    if prior.shape[0] == 0:\n","      append_job = bq.load_table_from_dataframe(\n","              dataframe = traffic_popular_paths,\n","              destination = bigquery.TableReference.from_string(f\"{BQ_PROJECT}.{BQ_DATASET}.traffic_popular_paths\"),\n","              job_config = bigquery.LoadJobConfig(\n","                  write_disposition = 'WRITE_APPEND',\n","                  autodetect = True, # detect schema\n","              ) \n","        )\n","      append_job.result()\n","\n","    # traffic_popular_referrers\n","    metric_type = 'traffic/popular/referrers'\n","    response = metric_get(metric_type)\n","    traffic_popular_referrers = pd.DataFrame(json.loads(response.text))\n","    traffic_popular_referrers['timestamp'] = datetime.now().strftime(\"%Y-%m-%dT00:00:00Z\") #strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n","    traffic_popular_referrers['repo'] = github_user + '/' + github_repo\n","    query = f\"\"\"\n","    SELECT *\n","    FROM `{BQ_PROJECT}.{BQ_DATASET}.traffic_popular_referrers`\n","    WHERE timestamp = '{traffic_popular_paths['timestamp'].max()}'\n","    ORDER BY count\n","    \"\"\"\n","    prior = bq.query(query = query).to_dataframe()\n","    if prior.shape[0] == 0:\n","      append_job = bq.load_table_from_dataframe(\n","              dataframe = traffic_popular_referrers,\n","              destination = bigquery.TableReference.from_string(f\"{BQ_PROJECT}.{BQ_DATASET}.traffic_popular_referrers\"),\n","              job_config = bigquery.LoadJobConfig(\n","                  write_disposition = 'WRITE_APPEND',\n","                  autodetect = True, # detect schema\n","              ) \n","        )\n","      append_job.result()\n","\n","    # traffic_views\n","    query = f\"\"\"\n","    SELECT t.*\n","    FROM `{BQ_PROJECT}.{BQ_DATASET}.traffic_views` t\n","    WHERE 1=1 QUALIFY row_number() OVER(ORDER BY timestamp DESC) = 1\n","    \"\"\"\n","    prior_traffic_views = bq.query(query = query).to_dataframe()\n","    metric_type = 'traffic/views'\n","    response = metric_get(metric_type)\n","    new_traffic_views = pd.DataFrame(json.loads(response.text)['views'])\n","    if new_traffic_views['timestamp'].iloc[-1] != datetime.now().strftime(\"%Y-%m-%dT00:00:00Z\"):\n","      # gap, likely due to no clones on a day, insert today with uniques clones\n","      new_traffic_views = new_traffic_views.append({'timestamp': datetime.now().strftime(\"%Y-%m-%dT00:00:00Z\"), 'count': 0, 'uniques': 0}, ignore_index = True).sort_values(by = ['timestamp'])\n","    new_traffic_views['uniques_last14days'] = np.nan\n","    new_traffic_views['uniques_last14days'].iloc[-1] = json.loads(response.text)['uniques']\n","    new_traffic_views['repo'] = github_user + '/' + github_repo\n","    overlap_record = new_traffic_views[new_traffic_views['timestamp'] == prior_traffic_views['timestamp'].iloc[0]]\n","    new_records = new_traffic_views[new_traffic_views['timestamp'] > prior_traffic_views['timestamp'].iloc[0]]\n","    if overlap_record.shape[0] == 1:\n","      if overlap_record[['timestamp', 'count', 'uniques']].values.tolist() != prior_traffic_views[['timestamp', 'count', 'uniques']].values.tolist():\n","        updated_record = overlap_record\n","        updated_record['uniques_last14days'].iloc[0] = prior_traffic_views['uniques_last14days'].iloc[0] \n","        new_records = pd.concat([updated_record, new_records], ignore_index = True, axis = 0)\n","        job = bq.query(query = f\"DELETE FROM `{BQ_PROJECT}.{BQ_DATASET}.traffic_views` WHERE timestamp = '{updated_record['timestamp'].iloc[0]}'\")\n","        job.result()\n","    if new_records.shape[0] >=1:\n","      append_job = bq.load_table_from_dataframe(\n","            dataframe = new_records,\n","            destination = bigquery.TableReference.from_string(f\"{BQ_PROJECT}.{BQ_DATASET}.traffic_views\"),\n","            job_config = bigquery.LoadJobConfig(\n","                write_disposition = 'WRITE_APPEND',\n","                autodetect = True, # detect schema\n","            ) \n","      )\n","      append_job.result()\n","\n","    # stargazers\n","    query = f\"\"\"\n","    SELECT *\n","    FROM `{BQ_PROJECT}.{BQ_DATASET}.stargazers`\n","    \"\"\"\n","    known = bq.query(query = query).to_dataframe()\n","    # list of expected active stargazers (> covers added and re-added, = covers added and never dropped)\n","    known_active = known[known['added'] >= known['dropped']]\n","    # list of known users in current state of dropped\n","    known_inactive = known[known['dropped'] > known['added']]\n","    metric_type = 'stargazers'\n","    page_size = 100\n","    page = 1\n","    raw = []\n","    while page_size == 100:\n","        response = metric_get(metric_type, f'?per_page={page_size}&page={page}')\n","        raw_new = json.loads(response.text)\n","        raw += raw_new\n","        page_size = len(raw_new)\n","        page += 1\n","    stargazers = pd.DataFrame(raw)[['login']]\n","    current = stargazers\n","    # newly added: in current but not in known\n","    newly_added = pd.DataFrame([x for x in current['login'].values.tolist() if x not in known['login'].values.tolist()], columns = ['login'])\n","    newly_added['added'] = datetime.now().strftime(\"%Y-%m-%dT00:00:00Z\")\n","    newly_added['dropped'] = ''\n","    newly_added['count'] = 1\n","    newly_added['repo'] = github_user + '/' + github_repo\n","    # newly dropped: in known_active but not in current\n","    newly_dropped = pd.DataFrame([x for x in known_active['login'].values.tolist() if x not in current['login'].values.tolist()], columns = ['login'])\n","    newly_dropped = pd.merge(known_active, newly_dropped, how = 'inner', on = ['login'])\n","    newly_dropped['dropped'] = datetime.now().strftime(\"%Y-%m-%dT00:00:00Z\")\n","    # newly readded: in current and in known_inactive\n","    newly_readded = pd.merge(current['login'], known_inactive['login'], how = 'inner', on = ['login'])\n","    newly_readded = pd.merge(newly_readded, known_inactive, how = 'inner', on = ['login'])\n","    newly_readded['added'] = datetime.now().strftime(\"%Y-%m-%dT00:00:00Z\")\n","    newly_readded['count'] = newly_readded['count'] + 1\n","    # newly combo\n","    new_records = pd.concat([newly_added, newly_dropped, newly_readded], ignore_index = True, axis = 0)\n","    stargazers_update = False\n","    if new_records.shape[0] >= 1:\n","      job = bq.query(query = f\"\"\"DELETE FROM `{BQ_PROJECT}.{BQ_DATASET}.stargazers` WHERE login in ({', '.join([f\"'{x}'\" for x in new_records['login'].values.tolist()])})\"\"\")\n","      job.result()\n","      append_job = bq.load_table_from_dataframe(\n","            dataframe = new_records,\n","            destination = bigquery.TableReference.from_string(f\"{BQ_PROJECT}.{BQ_DATASET}.stargazers\"),\n","            job_config = bigquery.LoadJobConfig(\n","                write_disposition = 'WRITE_APPEND',\n","                autodetect = True, # detect schema\n","            ) \n","      )\n","      append_job.result()\n","      stargazers_update = True\n","\n","    # forks\n","    query = f\"\"\"\n","    SELECT *\n","    FROM `{BQ_PROJECT}.{BQ_DATASET}.forks`\n","    \"\"\"\n","    known = bq.query(query = query).to_dataframe()\n","    # list of expected active stargazers (> covers added and re-added, = covers added and never dropped)\n","    known_active = known[known['added'] >= known['dropped']]\n","    # list of known users in current state of dropped\n","    known_inactive = known[known['dropped'] > known['added']]\n","    metric_type = 'forks'\n","    page_size = 100\n","    page = 1\n","    raw = []\n","    while page_size == 100:\n","        response = metric_get(metric_type, f'?per_page={page_size}&page={page}')\n","        raw_new = json.loads(response.text)\n","        raw += raw_new\n","        page_size = len(raw_new)\n","        page += 1\n","    forks = []\n","    for f in raw:\n","        forks += [{\n","            'name': f['name'],\n","            'full_name': f['full_name'],\n","            'owner': f['owner']['login'],\n","            'stars': f['stargazers_count'],\n","            'watchers': f['watchers_count'],\n","            'forks': f['forks_count']\n","        }]\n","    forks = pd.DataFrame(forks)\n","    current = forks\n","    # newly added: in current but not in known\n","    newly_added = pd.DataFrame([x for x in current['full_name'].values.tolist() if x not in known['full_name'].values.tolist()], columns = ['full_name'])\n","    newly_added = pd.merge(newly_added, current, how = 'inner', on = ['full_name'])\n","    newly_added['added'] = datetime.now().strftime(\"%Y-%m-%dT00:00:00Z\")\n","    newly_added['dropped'] = ''\n","    newly_added['count'] = 1\n","    newly_added['repo'] = github_user + '/' + github_repo\n","    # newly dropped: in known_active but not in current\n","    newly_dropped = pd.DataFrame([x for x in known_active['full_name'].values.tolist() if x not in current['full_name'].values.tolist()], columns = ['full_name'])\n","    newly_dropped = pd.merge(known_active, newly_dropped, how = 'inner', on = ['full_name'])\n","    newly_dropped['dropped'] = datetime.now().strftime(\"%Y-%m-%dT00:00:00Z\")\n","    # newly readded: in current and in known_inactive\n","    newly_readded = pd.merge(current['full_name'], known_inactive['full_name'], how = 'inner', on = ['full_name'])\n","    newly_readded = pd.merge(newly_readded, known_inactive, how = 'inner', on = ['full_name'])\n","    newly_readded['added'] = datetime.now().strftime(\"%Y-%m-%dT00:00:00Z\")\n","    newly_readded['count'] = newly_readded['count'] + 1\n","    # newly combo\n","    new_records = pd.concat([newly_added, newly_dropped, newly_readded], ignore_index = True, axis = 0)\n","    # start with outer merge on all columns in current\n","    non_match = pd.merge(known_active, current, how = 'outer', indicator = True, left_on = ['full_name', 'stars', 'watchers', 'forks'], right_on = ['full_name', 'stars', 'watchers', 'forks'])\n","    # make list of full_name that did not have an exact match in current - these need updating\n","    non_match = non_match[non_match._merge == 'left_only']\n","    non_match = non_match[['full_name']]\n","    # now get current records for the non_match\n","    non_match = pd.merge(non_match, current, how = 'inner', on = ['full_name'])\n","    # now get updated records\n","    updated_records = pd.merge(known_active[['name', 'full_name', 'owner', 'added', 'dropped', 'count', 'repo']], non_match[['full_name', 'stars', 'watchers', 'forks']], how = 'inner', on = 'full_name')\n","    # stack updated records with the new_records before updating\n","    new_records = pd.concat([updated_records, new_records], ignore_index = True, axis = 0)\n","    forks_update = False\n","    if new_records.shape[0] >= 1:\n","      job = bq.query(query = f\"\"\"DELETE FROM `{BQ_PROJECT}.{BQ_DATASET}.forks` WHERE full_name in ({', '.join([f\"'{x}'\" for x in new_records['full_name'].values.tolist()])})\"\"\")\n","      job.result()\n","      append_job = bq.load_table_from_dataframe(\n","            dataframe = new_records,\n","            destination = bigquery.TableReference.from_string(f\"{BQ_PROJECT}.{BQ_DATASET}.forks\"),\n","            job_config = bigquery.LoadJobConfig(\n","                write_disposition = 'WRITE_APPEND',\n","                autodetect = True, # detect schema\n","            ) \n","      )\n","      append_job.result()\n","      forks_update = True\n","\n","    # subscribers\n","    query = f\"\"\"\n","    SELECT *\n","    FROM `{BQ_PROJECT}.{BQ_DATASET}.subscribers`\n","    \"\"\"\n","    known = bq.query(query = query).to_dataframe()\n","    # list of expected active stargazers (> covers added and re-added, = covers added and never dropped)\n","    known_active = known[known['added'] >= known['dropped']]\n","    # list of known users in current state of dropped\n","    known_inactive = known[known['dropped'] > known['added']]\n","    metric_type = 'subscribers'\n","    page_size = 100\n","    page = 1\n","    raw = []\n","    while page_size == 100:\n","        response = metric_get(metric_type, f'?per_page={page_size}&page={page}')\n","        raw_new = json.loads(response.text)\n","        raw += raw_new\n","        page_size = len(raw_new)\n","        page += 1\n","    subscribers = pd.DataFrame(raw)[['login']]\n","    current = subscribers\n","    # newly added: in current but not in known\n","    newly_added = pd.DataFrame([x for x in current['login'].values.tolist() if x not in known['login'].values.tolist()], columns = ['login'])\n","    newly_added['added'] = datetime.now().strftime(\"%Y-%m-%dT00:00:00Z\")\n","    newly_added['dropped'] = ''\n","    newly_added['count'] = 1\n","    newly_added['repo'] = github_user + '/' + github_repo\n","    # newly dropped: in known_active but not in current\n","    newly_dropped = pd.DataFrame([x for x in known_active['login'].values.tolist() if x not in current['login'].values.tolist()], columns = ['login'])\n","    newly_dropped = pd.merge(known_active, newly_dropped, how = 'inner', on = ['login'])\n","    newly_dropped['dropped'] = datetime.now().strftime(\"%Y-%m-%dT00:00:00Z\")\n","    # newly readded: in current and in known_inactive\n","    newly_readded = pd.merge(current['login'], known_inactive['login'], how = 'inner', on = ['login'])\n","    newly_readded = pd.merge(newly_readded, known_inactive, how = 'inner', on = ['login'])\n","    newly_readded['added'] = datetime.now().strftime(\"%Y-%m-%dT00:00:00Z\")\n","    newly_readded['count'] = newly_readded['count'] + 1\n","    # newly combo\n","    new_records = pd.concat([newly_added, newly_dropped, newly_readded], ignore_index = True, axis = 0)\n","    subscribers_update = False\n","    if new_records.shape[0] > 1:\n","      job = bq.query(query = f\"\"\"DELETE FROM `{BQ_PROJECT}.{BQ_DATASET}.subscribers` WHERE login in ({', '.join([f\"'{x}'\" for x in new_records['login'].values.tolist()])})\"\"\")\n","      job.result()\n","      append_job = bq.load_table_from_dataframe(\n","            dataframe = new_records,\n","            destination = bigquery.TableReference.from_string(f\"{BQ_PROJECT}.{BQ_DATASET}.subscribers\"),\n","            job_config = bigquery.LoadJobConfig(\n","                write_disposition = 'WRITE_APPEND',\n","                autodetect = True, # detect schema\n","            ) \n","      )\n","      append_job.result()\n","      subscribers_update = True\n","      \n","\n","    # END: Content from notebook: GitHub Metrics - 1 - Traffic\n","    # START: Content from notebook: GitHub Metrics - 2 - Traffic\n","\n","    query = f\"\"\"\n","      DELETE FROM `vertex-ai-mlops-369716.reporting.github_traffic_clones` WHERE timestamp >= DATETIME(TIMESTAMP('2023-02-27T00:00:00Z'));\n","      INSERT INTO `vertex-ai-mlops-369716.reporting.github_traffic_clones`\n","      SELECT * EXCEPT(timestamp),\n","          DATETIME(TIMESTAMP(timestamp)) AS timestamp\n","      FROM `vertex-ai-mlops-369716.github_metrics.traffic_clones`\n","      WHERE timestamp >= '2023-02-27T00:00:00Z'\n","      ORDER BY timestamp;\n","\n","      DELETE FROM `vertex-ai-mlops-369716.reporting.github_traffic_popular_paths` WHERE timestamp >= DATETIME(TIMESTAMP('2023-02-27T00:00:00Z'));\n","      INSERT INTO `vertex-ai-mlops-369716.reporting.github_traffic_popular_paths`\n","      SELECT * EXCEPT(timestamp),\n","          DATETIME(TIMESTAMP(timestamp)) AS timestamp\n","      FROM `vertex-ai-mlops-369716.github_metrics.traffic_popular_paths`\n","      WHERE timestamp >= '2023-02-27T00:00:00Z'\n","      ORDER BY timestamp, count DESC;\n","\n","      DELETE FROM `vertex-ai-mlops-369716.reporting.github_traffic_popular_referrers` WHERE timestamp >= DATETIME(TIMESTAMP('2023-02-27T00:00:00Z'));\n","      INSERT INTO `vertex-ai-mlops-369716.reporting.github_traffic_popular_referrers`\n","      SELECT * EXCEPT(timestamp),\n","          DATETIME(TIMESTAMP(timestamp)) AS timestamp\n","      FROM `vertex-ai-mlops-369716.github_metrics.traffic_popular_referrers`\n","      WHERE timestamp >= '2023-02-27T00:00:00Z'\n","      ORDER BY timestamp, count DESC;\n","\n","      DELETE FROM `vertex-ai-mlops-369716.reporting.github_traffic_views` WHERE timestamp >= DATETIME(TIMESTAMP('2023-02-27T00:00:00Z'));\n","      INSERT INTO `vertex-ai-mlops-369716.reporting.github_traffic_views`\n","      SELECT * EXCEPT(timestamp),\n","          DATETIME(TIMESTAMP(timestamp)) AS timestamp\n","      FROM `vertex-ai-mlops-369716.github_metrics.traffic_views`\n","      WHERE timestamp >= '2023-02-27T00:00:00Z'\n","      ORDER BY timestamp;\n","    \"\"\"\n","    job = bq.query(query = query)\n","    job.result()\n","    print(job.state)\n","\n","    if stargazers_update:\n","      query = f\"\"\"\n","        CREATE OR REPLACE TABLE `vertex-ai-mlops-369716.reporting.github_stargazers` AS\n","        SELECT * EXCEPT(added, dropped),\n","            CASE WHEN added = '' THEN NULL ELSE DATETIME(TIMESTAMP(added)) END AS added,\n","            CASE WHEN dropped = '' THEN NULL ELSE DATETIME(TIMESTAMP(dropped)) END AS dropped\n","        FROM `vertex-ai-mlops-369716.github_metrics.stargazers`\n","        WHERE added >= dropped\n","        ORDER BY login;\n","      \"\"\"\n","      job = bq.query(query = query)\n","      job.result()\n","      print(job.state)\n","    \n","    if forks_update:\n","      query = f\"\"\"\n","        CREATE OR REPLACE TABLE `vertex-ai-mlops-369716.reporting.github_forks` AS\n","        SELECT * EXCEPT(added, dropped),\n","            CASE WHEN added = '' THEN NULL ELSE DATETIME(TIMESTAMP(added)) END AS added,\n","            CASE WHEN dropped = '' THEN NULL ELSE DATETIME(TIMESTAMP(dropped)) END AS dropped\n","        FROM `vertex-ai-mlops-369716.github_metrics.forks`\n","        WHERE added >= dropped\n","        ORDER BY full_name;\n","      \"\"\"\n","      job = bq.query(query = query)\n","      job.result()\n","      print(job.state)\n","\n","    if subscribers_update:\n","      query = f\"\"\"\n","        CREATE OR REPLACE TABLE `vertex-ai-mlops-369716.reporting.github_subscribers` AS\n","        SELECT * EXCEPT(added, dropped),\n","            CASE WHEN added = '' THEN NULL ELSE DATETIME(TIMESTAMP(added)) END AS added,\n","            CASE WHEN dropped = '' THEN NULL ELSE DATETIME(TIMESTAMP(dropped)) END AS dropped\n","        FROM `vertex-ai-mlops-369716.github_metrics.subscribers`\n","        WHERE added >= dropped\n","        ORDER BY login;\n","      \"\"\"\n","      job = bq.query(query = query)\n","      job.result()\n","      print(job.state)\n","\n","    # END: Content from notebook: GitHub Metrics - 2 - Traffic"]},{"cell_type":"code","execution_count":70,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":184,"status":"ok","timestamp":1677608501010,"user":{"displayName":"Mike Henderson","userId":"11664017018095232389"},"user_tz":300},"id":"XKMFg981bFFE","outputId":"c42ae67b-d724-4e81-b0b6-63a009b7fd0a"},"outputs":[{"output_type":"stream","name":"stdout","text":["main.py  requirements.txt\n"]}],"source":["!ls {DIR}/function"]},{"cell_type":"markdown","metadata":{"id":"9AoZW8nLhQGW"},"source":["### Zip Files"]},{"cell_type":"code","execution_count":71,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1677608502379,"user":{"displayName":"Mike Henderson","userId":"11664017018095232389"},"user_tz":300},"id":"0gWHs48VbFCp"},"outputs":[],"source":["import zipfile\n","with zipfile.ZipFile(f'{DIR}/function/function_traffic.zip', mode = 'w') as archive:\n","    archive.write(f'{DIR}/function/main.py', 'main.py')\n","    archive.write(f'{DIR}/function/requirements.txt', 'requirements.txt')"]},{"cell_type":"code","execution_count":72,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":194,"status":"ok","timestamp":1677608502569,"user":{"displayName":"Mike Henderson","userId":"11664017018095232389"},"user_tz":300},"id":"Z7159ULTbFBA","outputId":"d8bb414e-6b8a-460b-f868-132374635da4"},"outputs":[{"output_type":"stream","name":"stdout","text":["function_traffic.zip  main.py  requirements.txt\n"]}],"source":["!ls {DIR}/function"]},{"cell_type":"code","execution_count":73,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1677608502570,"user":{"displayName":"Mike Henderson","userId":"11664017018095232389"},"user_tz":300},"id":"TFsp0r0PbE-B","outputId":"3dbf979a-4b70-438d-df33-79b6d944e2a6"},"outputs":[{"output_type":"stream","name":"stdout","text":["File Name                                             Modified             Size\n","main.py                                        2023-02-28 18:21:40        21728\n","requirements.txt                               2023-02-28 18:21:40           39\n"]}],"source":["with zipfile.ZipFile(f'{DIR}/function/function_traffic.zip', mode = 'r') as zip:\n","    zip.printdir()"]},{"cell_type":"markdown","metadata":{"id":"iioImcxihT5S"},"source":["### Move Files to GCS\n","\n","Expects a bucket with the same name as the project:"]},{"cell_type":"code","execution_count":74,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1677608502776,"user":{"displayName":"Mike Henderson","userId":"11664017018095232389"},"user_tz":300},"id":"8K7w_jQ1bE6n"},"outputs":[],"source":["bucket = gcs.bucket(PROJECT_ID)"]},{"cell_type":"code","execution_count":75,"metadata":{"executionInfo":{"elapsed":265,"status":"ok","timestamp":1677608503340,"user":{"displayName":"Mike Henderson","userId":"11664017018095232389"},"user_tz":300},"id":"FAWndgwxlyVd"},"outputs":[],"source":["SOURCEPATH = f'architectures/tracking/setup/github'\n","blob = bucket.blob(f'{SOURCEPATH}/function_traffic.zip')\n","blob.upload_from_filename(f'{DIR}/function/function_traffic.zip')"]},{"cell_type":"code","execution_count":76,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1677608503716,"user":{"displayName":"Mike Henderson","userId":"11664017018095232389"},"user_tz":300},"id":"V9KkgKA6lzkE","outputId":"99a27c06-7966-412a-f424-b8fe83e875f4"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<Blob: vertex-ai-mlops-369716, architectures/tracking/setup/github/function_commit.zip, 1677586594050541>,\n"," <Blob: vertex-ai-mlops-369716, architectures/tracking/setup/github/function_traffic.zip, 1677608503169177>]"]},"metadata":{},"execution_count":76}],"source":["list(bucket.list_blobs(prefix = f'{SOURCEPATH}'))"]},{"cell_type":"code","execution_count":77,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1677608504445,"user":{"displayName":"Mike Henderson","userId":"11664017018095232389"},"user_tz":300},"id":"ZSLvyEQdlzhh","outputId":"1e690725-ec5c-4ed3-e82c-e191031b0196"},"outputs":[{"output_type":"stream","name":"stdout","text":["View the bucket directly here:\n","https://console.cloud.google.com/storage/browser/vertex-ai-mlops-369716/architectures/tracking/setup/github;tab=objects&project=vertex-ai-mlops-369716\n"]}],"source":["print(f\"View the bucket directly here:\\nhttps://console.cloud.google.com/storage/browser/{PROJECT_ID}/{SOURCEPATH};tab=objects&project={PROJECT_ID}\")"]},{"cell_type":"markdown","metadata":{"id":"VF7cLwtSvrQw"},"source":["### Service Account\n","The Cloud Function will run as a service account.  Retrieve the default app engine service account and check its permissions.  It needs to be able to read/write to BigQuery and read secrets from the secret manager.\n","\n","I used the Console to create a service account for these jobs:\n","- Console > IAM > Service Accounts\n","- Create New: name = `metrics-runner`\n","- roles = BigQuery Admin, Secret Accessor\n","\n"]},{"cell_type":"code","execution_count":78,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1677608504602,"user":{"displayName":"Mike Henderson","userId":"11664017018095232389"},"user_tz":300},"id":"KmzXT6wa6rNJ","outputId":"122395ef-277a-44af-cec3-652ff9ae9ad3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Review Service Account Details in Console:\n","https://console.cloud.google.com/iam-admin/serviceaccounts?project=vertex-ai-mlops-369716\n"]}],"source":["print(f'Review Service Account Details in Console:\\nhttps://console.cloud.google.com/iam-admin/serviceaccounts?project={PROJECT_ID}')"]},{"cell_type":"markdown","metadata":{"id":"38-1ERqwmyUZ"},"source":["### Create (or Update) Cloud Function"]},{"cell_type":"code","execution_count":79,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1677608505148,"user":{"displayName":"Mike Henderson","userId":"11664017018095232389"},"user_tz":300},"id":"olE04Uw0lzfw"},"outputs":[],"source":["function_name = f'github_metrics_traffic'"]},{"cell_type":"code","execution_count":80,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1677608505741,"user":{"displayName":"Mike Henderson","userId":"11664017018095232389"},"user_tz":300},"id":"lCPBjqQwlzdN"},"outputs":[],"source":["function = ''\n","for function in functions_client.list_functions(request = functions_v1.ListFunctionsRequest(parent = f'projects/{PROJECT_ID}/locations/{REGION}')):\n","    if function.name.endswith(function_name):\n","        break\n","    else: function = ''"]},{"cell_type":"code","execution_count":81,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1677608506531,"user":{"displayName":"Mike Henderson","userId":"11664017018095232389"},"user_tz":300},"id":"Hdjvp8HLnC8d","outputId":"bb51ce30-922e-4fc5-a01e-bd3385a6163d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["name: \"projects/vertex-ai-mlops-369716/locations/us-central1/functions/github_metrics_traffic\"\n","source_archive_url: \"gs://vertex-ai-mlops-369716/architectures/tracking/setup/github/function_traffic.zip\"\n","event_trigger {\n","  event_type: \"providers/cloud.pubsub/eventTypes/topic.publish\"\n","  resource: \"projects/vertex-ai-mlops-369716/topics/daily_metrics_triggers\"\n","  service: \"pubsub.googleapis.com\"\n","  failure_policy {\n","  }\n","}\n","status: ACTIVE\n","entry_point: \"collect\"\n","timeout {\n","  seconds: 420\n","}\n","available_memory_mb: 256\n","service_account_email: \"metrics-runner@vertex-ai-mlops-369716.iam.gserviceaccount.com\"\n","update_time {\n","  seconds: 1677608354\n","  nanos: 641000000\n","}\n","version_id: 2\n","runtime: \"python310\"\n","max_instances: 3000\n","ingress_settings: ALLOW_ALL\n","build_id: \"0bb482d9-7c11-4847-9bae-bf2988cc8c70\"\n","secret_environment_variables {\n","  key: \"GITHUB_PAT\"\n","  project_id: \"807305962454\"\n","  secret: \"github_api\"\n","  version: \"latest\"\n","}\n","build_name: \"projects/807305962454/locations/us-central1/builds/0bb482d9-7c11-4847-9bae-bf2988cc8c70\"\n","docker_registry: CONTAINER_REGISTRY"]},"metadata":{},"execution_count":81}],"source":["function"]},{"cell_type":"code","execution_count":82,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1677608510424,"user":{"displayName":"Mike Henderson","userId":"11664017018095232389"},"user_tz":300},"id":"c9e88xwClzbV"},"outputs":[],"source":["from google.protobuf.duration_pb2 import Duration\n","\n","functionDef = functions_v1.CloudFunction()\n","functionDef.name = f'projects/{PROJECT_ID}/locations/{REGION}/functions/{function_name}'\n","functionDef.source_archive_url = f\"gs://{PROJECT_ID}/{SOURCEPATH}/function_traffic.zip\"\n","functionDef.event_trigger = functions_v1.EventTrigger()\n","functionDef.event_trigger.event_type = 'providers/cloud.pubsub/eventTypes/topic.publish'\n","functionDef.event_trigger.resource = topic.name\n","functionDef.runtime = 'python310'\n","functionDef.entry_point = 'collect'\n","functionDef.timeout = Duration(seconds = 420)\n","functionDef.service_account_email = f\"metrics-runner@{PROJECT_ID}.iam.gserviceaccount.com\"\n","functionDef.secret_environment_variables = [functions_v1.SecretEnvVar(\n","    key = 'GITHUB_PAT',\n","    secret = 'github_api'\n",")]"]},{"cell_type":"code","execution_count":83,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1677608510568,"user":{"displayName":"Mike Henderson","userId":"11664017018095232389"},"user_tz":300},"id":"VkQ9l8AYlzY9","outputId":"c45f2ad3-b587-4532-ab8c-d1f47ced30c0"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["name: \"projects/vertex-ai-mlops-369716/locations/us-central1/functions/github_metrics_traffic\"\n","source_archive_url: \"gs://vertex-ai-mlops-369716/architectures/tracking/setup/github/function_traffic.zip\"\n","event_trigger {\n","  event_type: \"providers/cloud.pubsub/eventTypes/topic.publish\"\n","  resource: \"projects/vertex-ai-mlops-369716/topics/daily_metrics_triggers\"\n","}\n","entry_point: \"collect\"\n","timeout {\n","  seconds: 420\n","}\n","service_account_email: \"metrics-runner@vertex-ai-mlops-369716.iam.gserviceaccount.com\"\n","runtime: \"python310\"\n","secret_environment_variables {\n","  key: \"GITHUB_PAT\"\n","  secret: \"github_api\"\n","}"]},"metadata":{},"execution_count":83}],"source":["functionDef"]},{"cell_type":"code","execution_count":84,"metadata":{"executionInfo":{"elapsed":1051,"status":"ok","timestamp":1677608512518,"user":{"displayName":"Mike Henderson","userId":"11664017018095232389"},"user_tz":300},"id":"OomTBZM-lzWP"},"outputs":[],"source":["if function:\n","    request = functions_v1.UpdateFunctionRequest(\n","        function = functionDef\n","    )\n","    operation = functions_client.update_function(request = request)\n","else:\n","    request = functions_v1.CreateFunctionRequest(\n","        location = f\"projects/{PROJECT_ID}/locations/{REGION}\",\n","        function = functionDef\n","    )\n","    operation = functions_client.create_function(request = request)"]},{"cell_type":"code","execution_count":85,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":155431,"status":"ok","timestamp":1677608668130,"user":{"displayName":"Mike Henderson","userId":"11664017018095232389"},"user_tz":300},"id":"aFeoweDQlzS5","outputId":"67a6932b-50a4-4409-d80b-956a41a0d2dc"},"outputs":[{"output_type":"stream","name":"stdout","text":["name: \"projects/vertex-ai-mlops-369716/locations/us-central1/functions/github_metrics_traffic\"\n","source_archive_url: \"gs://vertex-ai-mlops-369716/architectures/tracking/setup/github/function_traffic.zip\"\n","event_trigger {\n","  event_type: \"providers/cloud.pubsub/eventTypes/topic.publish\"\n","  resource: \"projects/vertex-ai-mlops-369716/topics/daily_metrics_triggers\"\n","  service: \"pubsub.googleapis.com\"\n","  failure_policy {\n","  }\n","}\n","status: ACTIVE\n","entry_point: \"collect\"\n","timeout {\n","  seconds: 420\n","}\n","available_memory_mb: 256\n","service_account_email: \"metrics-runner@vertex-ai-mlops-369716.iam.gserviceaccount.com\"\n","update_time {\n","  seconds: 1677608667\n","  nanos: 126000000\n","}\n","version_id: 3\n","runtime: \"python310\"\n","max_instances: 3000\n","ingress_settings: ALLOW_ALL\n","build_id: \"c978ef09-74be-4ca3-b367-fb733d65133d\"\n","secret_environment_variables {\n","  key: \"GITHUB_PAT\"\n","  project_id: \"807305962454\"\n","  secret: \"github_api\"\n","  version: \"latest\"\n","}\n","build_name: \"projects/807305962454/locations/us-central1/builds/c978ef09-74be-4ca3-b367-fb733d65133d\"\n","docker_registry: CONTAINER_REGISTRY\n","\n"]}],"source":["response = operation.result()\n","print(response)"]},{"cell_type":"code","execution_count":86,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1677608668130,"user":{"displayName":"Mike Henderson","userId":"11664017018095232389"},"user_tz":300},"id":"pYRzg_23lzQg","outputId":"5dad2ad6-8578-45e2-9f5c-44360918356b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Review the Cloud Function in the console here:\n","https://console.cloud.google.com/functions/list?env=gen1&project=vertex-ai-mlops-369716\n"]}],"source":["print(f'Review the Cloud Function in the console here:\\nhttps://console.cloud.google.com/functions/list?env=gen1&project={PROJECT_ID}')"]},{"cell_type":"markdown","metadata":{"id":"09eF9DPCqPDF"},"source":["### Manual Run of Cloud Function\n","\n","Publish a message to the Pub/Sub topic that will cause the Cloud Function to initiate training.  The code below could be anywhere you want to trigger training!\n","\n","The function will receive the message as `event` in the format:\n","```\n","{\n","    '@type': 'type.googleapis.com/google.pubsub.v1.PubsubMessage',\n","    'attributes': {'key' : 'value', ...},\n","    'data': <base64 encoded string>\n","}\n","```\n","\n","To handle the `event` and retrieve the inputs of the message three things need to happen:\n","1. reference the 'data' value as `event['data']`\n","2. decode the 'data' value with `base64.b64decode(<1>).decode('utf-8')`\n","3. convert the decoded string into a Python dictionary with `json.loads(<2>)`\n","\n","This looks like:\n","```\n","funtion_inputs = json.loads(base64.b64decode(event['data']).decode('utf-8'))\n","```"]},{"cell_type":"code","execution_count":87,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1677608668131,"user":{"displayName":"Mike Henderson","userId":"11664017018095232389"},"user_tz":300},"id":"YLvUdDCUlzNa"},"outputs":[],"source":["function_input = {\n","    'PROJECT_ID': PROJECT_ID\n","}"]},{"cell_type":"code","execution_count":88,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1677608668131,"user":{"displayName":"Mike Henderson","userId":"11664017018095232389"},"user_tz":300},"id":"NRiUp32ElzKk"},"outputs":[],"source":["message = json.dumps(function_input)\n","message = message.encode('utf-8')"]},{"cell_type":"code","execution_count":89,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1677608668131,"user":{"displayName":"Mike Henderson","userId":"11664017018095232389"},"user_tz":300},"id":"5iVY4blUnLJy"},"outputs":[],"source":["future = pubsub_pubclient.publish(topic.name, message, trigger = 'manual')"]},{"cell_type":"code","execution_count":90,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":188,"status":"ok","timestamp":1677608668303,"user":{"displayName":"Mike Henderson","userId":"11664017018095232389"},"user_tz":300},"id":"g0El69aJnLGc","outputId":"ea02cc8e-cb8f-4789-faa4-b860a2505941"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'7008586715462781'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":90}],"source":["future.result()"]},{"cell_type":"markdown","metadata":{"id":"sIldXzPpqftI"},"source":["---\n","## Scheduled Run with Cloud Scheduler\n","\n","Use Cloud Scheduler to publish a message to the topic at any defined interval which will cause the Cloud Function to initiate training.\n","\n","Resources:\n","- List of Time zones - [TZ Database Names](https://en.wikipedia.org/wiki/List_of_tz_database_time_zones)\n","- Job Frequency - [unix-cron format guide](https://man7.org/linux/man-pages/man5/crontab.5.html)\n","    - minute hour day_of_month month day_of_week\n","    - 0 23 * * tue = 11PM every Tuesday\n"]},{"cell_type":"code","execution_count":91,"metadata":{"id":"j5E3Is9hnLCV","executionInfo":{"status":"ok","timestamp":1677608851892,"user_tz":300,"elapsed":185,"user":{"displayName":"Mike Henderson","userId":"11664017018095232389"}}},"outputs":[],"source":["schedule_name = 'daily_3am_est'"]},{"cell_type":"code","execution_count":92,"metadata":{"id":"BKdJXugMnLAE","executionInfo":{"status":"ok","timestamp":1677608854169,"user_tz":300,"elapsed":501,"user":{"displayName":"Mike Henderson","userId":"11664017018095232389"}}},"outputs":[],"source":["schedule = ''\n","for schedule in scheduler_client.list_jobs(parent = f'projects/{PROJECT_ID}/locations/{REGION}'):\n","    if schedule.name.endswith(schedule_name):\n","        break\n","    else: schedule = ''"]},{"cell_type":"code","execution_count":93,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":145,"status":"ok","timestamp":1677608867795,"user":{"displayName":"Mike Henderson","userId":"11664017018095232389"},"user_tz":300},"id":"LCc7ponWnK-F","outputId":"0701df5f-f93d-4f28-c718-f971fa9f027f"},"outputs":[{"output_type":"stream","name":"stdout","text":["name: \"projects/vertex-ai-mlops-369716/locations/us-central1/jobs/daily_3am_est\"\n","pubsub_target {\n","  topic_name: \"projects/vertex-ai-mlops-369716/topics/daily_metrics_triggers\"\n","  data: \"{\\\"PROJECT_ID\\\": \\\"vertex-ai-mlops-369716\\\"}\"\n","  attributes {\n","    key: \"trigger\"\n","    value: \"scheduled\"\n","  }\n","}\n","user_update_time {\n","  seconds: 1676847544\n","}\n","state: ENABLED\n","status {\n","}\n","schedule_time {\n","  seconds: 1677657600\n","  nanos: 855718000\n","}\n","last_attempt_time {\n","  seconds: 1677571200\n","  nanos: 689748000\n","}\n","schedule: \"0 3 * * *\"\n","time_zone: \"America/New_York\"\n","\n"]}],"source":["if schedule:\n","    print(schedule)\n","else:\n","    request = scheduler_v1.CreateJobRequest(\n","        parent = f'projects/{PROJECT_ID}/locations/{REGION}',\n","        job = scheduler_v1.Job(\n","            name = f'projects/{PROJECT_ID}/locations/{REGION}/jobs/{schedule_name}',\n","            pubsub_target = scheduler_v1.PubsubTarget(\n","                topic_name = topic.name,\n","                data = message,\n","                attributes = {'trigger': 'scheduled'}\n","            ),\n","            schedule = '0 3 * * *',\n","            time_zone = 'America/New_York'\n","        )\n","    )\n","    schedule = scheduler_client.create_job(request = request)\n","    print(schedule)"]},{"cell_type":"code","execution_count":94,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":152,"status":"ok","timestamp":1677608871738,"user":{"displayName":"Mike Henderson","userId":"11664017018095232389"},"user_tz":300},"id":"-OlK0diknK7q","outputId":"b8d1f554-4dfd-425c-924f-2a53a3961e01"},"outputs":[{"output_type":"stream","name":"stdout","text":["Review the schedule in the console:\n","https://console.cloud.google.com/cloudscheduler?project=vertex-ai-mlops-369716\n"]}],"source":["print(f'Review the schedule in the console:\\nhttps://console.cloud.google.com/cloudscheduler?project={PROJECT_ID}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CS_HXRUanK5d"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ASmMNNQvnK2k"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VwI00glLnKz8"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[],"toc_visible":true},"environment":{"kernel":"python3","name":"tf2-gpu.2-3.m94","type":"gcloud","uri":"gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m94"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":0}